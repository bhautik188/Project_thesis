
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-06-11 16:08:54.477281: Using torch.compile... 
2025-06-11 16:08:58.885259: do_dummy_2d_data_aug: False 
2025-06-11 16:08:58.887021: Creating new 5-fold cross-validation split... 
2025-06-11 16:08:58.889830: Desired fold for training: 0 
2025-06-11 16:08:58.890332: This split has 84 training and 21 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 66, 'patch_size': [224, 224], 'median_image_size_in_voxels': [196.0, 199.0], 'spacing': [1.4423099756240845, 1.4423099756240845], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_VesselDetection', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [5.0, 1.4423099756240845, 1.4423099756240845], 'original_median_shape_after_transp': [1, 196, 199], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 332.0, 'mean': 181.2578125, 'median': 181.0, 'min': 0.0, 'percentile_00_5': 1.0, 'percentile_99_5': 323.0, 'std': 55.323936462402344}}} 
 
2025-06-11 16:09:02.195115: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-06-11 16:09:02.276102:  
2025-06-11 16:09:02.278970: Epoch 0 
2025-06-11 16:09:02.280348: Current learning rate: 0.01 
2025-06-11 16:12:49.993318: train_loss 0.0445 
2025-06-11 16:12:49.994894: val_loss -0.0324 
2025-06-11 16:12:49.995415: Pseudo dice [np.float32(0.0482)] 
2025-06-11 16:12:49.996208: Epoch time: 227.74 s 
2025-06-11 16:12:49.996694: Yayy! New best EMA pseudo Dice: 0.04820000007748604 
2025-06-11 16:12:52.826188:  
2025-06-11 16:12:52.827097: Epoch 1 
2025-06-11 16:12:52.827719: Current learning rate: 0.00996 
2025-06-11 16:14:17.797473: train_loss -0.1459 
2025-06-11 16:14:17.799481: val_loss -0.4564 
2025-06-11 16:14:17.800179: Pseudo dice [np.float32(0.4468)] 
2025-06-11 16:14:17.800888: Epoch time: 84.97 s 
2025-06-11 16:14:17.801717: Yayy! New best EMA pseudo Dice: 0.08799999952316284 
2025-06-11 16:14:20.349050:  
2025-06-11 16:14:20.349798: Epoch 2 
2025-06-11 16:14:20.350299: Current learning rate: 0.00993 
2025-06-11 16:15:45.928423: train_loss -0.7091 
2025-06-11 16:15:45.929889: val_loss -0.7862 
2025-06-11 16:15:45.930357: Pseudo dice [np.float32(0.8593)] 
2025-06-11 16:15:45.930880: Epoch time: 85.58 s 
2025-06-11 16:15:45.931477: Yayy! New best EMA pseudo Dice: 0.16509999334812164 
2025-06-11 16:15:48.423739:  
2025-06-11 16:15:48.424525: Epoch 3 
2025-06-11 16:15:48.425121: Current learning rate: 0.00989 
2025-06-11 16:17:14.004259: train_loss -0.799 
2025-06-11 16:17:14.005518: val_loss -0.8039 
2025-06-11 16:17:14.006021: Pseudo dice [np.float32(0.8601)] 
2025-06-11 16:17:14.006513: Epoch time: 85.58 s 
2025-06-11 16:17:14.007210: Yayy! New best EMA pseudo Dice: 0.2345999926328659 
2025-06-11 16:17:16.468893:  
2025-06-11 16:17:16.469729: Epoch 4 
2025-06-11 16:17:16.470592: Current learning rate: 0.00986 
2025-06-11 16:18:41.963639: train_loss -0.8148 
2025-06-11 16:18:41.964913: val_loss -0.8031 
2025-06-11 16:18:41.965364: Pseudo dice [np.float32(0.8747)] 
2025-06-11 16:18:41.965862: Epoch time: 85.5 s 
2025-06-11 16:18:41.966308: Yayy! New best EMA pseudo Dice: 0.2987000048160553 
2025-06-11 16:18:44.445553:  
2025-06-11 16:18:44.446221: Epoch 5 
2025-06-11 16:18:44.446728: Current learning rate: 0.00982 
2025-06-11 16:20:09.926805: train_loss -0.8221 
2025-06-11 16:20:09.928292: val_loss -0.8091 
2025-06-11 16:20:09.928955: Pseudo dice [np.float32(0.8707)] 
2025-06-11 16:20:09.929496: Epoch time: 85.48 s 
2025-06-11 16:20:09.929995: Yayy! New best EMA pseudo Dice: 0.35589998960494995 
2025-06-11 16:20:12.350012:  
2025-06-11 16:20:12.350902: Epoch 6 
2025-06-11 16:20:12.351426: Current learning rate: 0.00978 
2025-06-11 16:21:37.826608: train_loss -0.8288 
2025-06-11 16:21:37.828398: val_loss -0.8067 
2025-06-11 16:21:37.829131: Pseudo dice [np.float32(0.8676)] 
2025-06-11 16:21:37.829855: Epoch time: 85.48 s 
2025-06-11 16:21:37.830539: Yayy! New best EMA pseudo Dice: 0.40700000524520874 
2025-06-11 16:21:40.277177:  
2025-06-11 16:21:40.278049: Epoch 7 
2025-06-11 16:21:40.278644: Current learning rate: 0.00975 
2025-06-11 16:23:05.856086: train_loss -0.8565 
2025-06-11 16:23:05.857771: val_loss -0.866 
2025-06-11 16:23:05.858336: Pseudo dice [np.float32(0.868)] 
2025-06-11 16:23:05.858885: Epoch time: 85.58 s 
2025-06-11 16:23:05.859454: Yayy! New best EMA pseudo Dice: 0.4530999958515167 
2025-06-11 16:23:08.348384:  
2025-06-11 16:23:08.349202: Epoch 8 
2025-06-11 16:23:08.349738: Current learning rate: 0.00971 
2025-06-11 16:24:34.025839: train_loss -0.8841 
2025-06-11 16:24:34.027919: val_loss -0.8719 
2025-06-11 16:24:34.028799: Pseudo dice [np.float32(0.8705)] 
2025-06-11 16:24:34.029655: Epoch time: 85.68 s 
2025-06-11 16:24:34.030499: Yayy! New best EMA pseudo Dice: 0.4948999881744385 
2025-06-11 16:24:36.486718:  
2025-06-11 16:24:36.487393: Epoch 9 
2025-06-11 16:24:36.487923: Current learning rate: 0.00968 
2025-06-11 16:26:02.121836: train_loss -0.8898 
2025-06-11 16:26:02.123537: val_loss -0.8736 
2025-06-11 16:26:02.124107: Pseudo dice [np.float32(0.8807)] 
2025-06-11 16:26:02.124684: Epoch time: 85.64 s 
2025-06-11 16:26:02.125292: Yayy! New best EMA pseudo Dice: 0.5333999991416931 
2025-06-11 16:26:04.598986:  
2025-06-11 16:26:04.599690: Epoch 10 
2025-06-11 16:26:04.600373: Current learning rate: 0.00964 
2025-06-11 16:27:30.130989: train_loss -0.8923 
2025-06-11 16:27:30.132235: val_loss -0.8805 
2025-06-11 16:27:30.132693: Pseudo dice [np.float32(0.8783)] 
2025-06-11 16:27:30.133206: Epoch time: 85.53 s 
2025-06-11 16:27:30.133734: Yayy! New best EMA pseudo Dice: 0.5679000020027161 
2025-06-11 16:27:32.563482:  
2025-06-11 16:27:32.564479: Epoch 11 
2025-06-11 16:27:32.565136: Current learning rate: 0.0096 
2025-06-11 16:28:58.157038: train_loss -0.8969 
2025-06-11 16:28:58.158402: val_loss -0.8677 
2025-06-11 16:28:58.158892: Pseudo dice [np.float32(0.868)] 
2025-06-11 16:28:58.159428: Epoch time: 85.6 s 
2025-06-11 16:28:58.159936: Yayy! New best EMA pseudo Dice: 0.5978999733924866 
2025-06-11 16:29:00.585071:  
2025-06-11 16:29:00.586156: Epoch 12 
2025-06-11 16:29:00.586713: Current learning rate: 0.00957 
2025-06-11 16:30:26.268627: train_loss -0.8987 
2025-06-11 16:30:26.269893: val_loss -0.8782 
2025-06-11 16:30:26.270335: Pseudo dice [np.float32(0.8778)] 
2025-06-11 16:30:26.270763: Epoch time: 85.69 s 
2025-06-11 16:30:26.271262: Yayy! New best EMA pseudo Dice: 0.6258999705314636 
2025-06-11 16:30:28.691956:  
2025-06-11 16:30:28.692782: Epoch 13 
2025-06-11 16:30:28.693305: Current learning rate: 0.00953 
2025-06-11 16:31:54.172719: train_loss -0.9019 
2025-06-11 16:31:54.174351: val_loss -0.8746 
2025-06-11 16:31:54.175012: Pseudo dice [np.float32(0.8786)] 
2025-06-11 16:31:54.175621: Epoch time: 85.48 s 
2025-06-11 16:31:54.176357: Yayy! New best EMA pseudo Dice: 0.651199996471405 
2025-06-11 16:31:56.622044:  
2025-06-11 16:31:56.623570: Epoch 14 
2025-06-11 16:31:56.624202: Current learning rate: 0.00949 
2025-06-11 16:33:22.124870: train_loss -0.9045 
2025-06-11 16:33:22.126217: val_loss -0.8706 
2025-06-11 16:33:22.126678: Pseudo dice [np.float32(0.8631)] 
2025-06-11 16:33:22.127136: Epoch time: 85.51 s 
2025-06-11 16:33:22.127599: Yayy! New best EMA pseudo Dice: 0.6723999977111816 
2025-06-11 16:33:24.542506:  
2025-06-11 16:33:24.543190: Epoch 15 
2025-06-11 16:33:24.543952: Current learning rate: 0.00946 
2025-06-11 16:34:50.111800: train_loss -0.9064 
2025-06-11 16:34:50.113177: val_loss -0.879 
2025-06-11 16:34:50.113692: Pseudo dice [np.float32(0.8766)] 
2025-06-11 16:34:50.114240: Epoch time: 85.57 s 
2025-06-11 16:34:50.114731: Yayy! New best EMA pseudo Dice: 0.692799985408783 
2025-06-11 16:34:52.562290:  
2025-06-11 16:34:52.563021: Epoch 16 
2025-06-11 16:34:52.563631: Current learning rate: 0.00942 
2025-06-11 16:36:18.157576: train_loss -0.9097 
2025-06-11 16:36:18.159183: val_loss -0.8746 
2025-06-11 16:36:18.159888: Pseudo dice [np.float32(0.8706)] 
2025-06-11 16:36:18.160622: Epoch time: 85.6 s 
2025-06-11 16:36:18.161463: Yayy! New best EMA pseudo Dice: 0.7106000185012817 
2025-06-11 16:36:20.650922:  
2025-06-11 16:36:20.651674: Epoch 17 
2025-06-11 16:36:20.652274: Current learning rate: 0.00939 
2025-06-11 16:37:46.081645: train_loss -0.9115 
2025-06-11 16:37:46.083325: val_loss -0.8795 
2025-06-11 16:37:46.083881: Pseudo dice [np.float32(0.8759)] 
2025-06-11 16:37:46.084429: Epoch time: 85.43 s 
2025-06-11 16:37:46.084924: Yayy! New best EMA pseudo Dice: 0.7271000146865845 
2025-06-11 16:37:48.586520:  
2025-06-11 16:37:48.587331: Epoch 18 
2025-06-11 16:37:48.587947: Current learning rate: 0.00935 
2025-06-11 16:39:14.034567: train_loss -0.9144 
2025-06-11 16:39:14.036402: val_loss -0.8781 
2025-06-11 16:39:14.036914: Pseudo dice [np.float32(0.8742)] 
2025-06-11 16:39:14.037568: Epoch time: 85.45 s 
2025-06-11 16:39:14.038208: Yayy! New best EMA pseudo Dice: 0.7418000102043152 
2025-06-11 16:39:16.449224:  
2025-06-11 16:39:16.449996: Epoch 19 
2025-06-11 16:39:16.450529: Current learning rate: 0.00931 
2025-06-11 16:40:42.042231: train_loss -0.9149 
2025-06-11 16:40:42.044400: val_loss -0.879 
2025-06-11 16:40:42.045215: Pseudo dice [np.float32(0.8764)] 
2025-06-11 16:40:42.045775: Epoch time: 85.6 s 
2025-06-11 16:40:42.046423: Yayy! New best EMA pseudo Dice: 0.755299985408783 
2025-06-11 16:40:45.799823:  
2025-06-11 16:40:45.800491: Epoch 20 
2025-06-11 16:40:45.801114: Current learning rate: 0.00928 
2025-06-11 16:42:11.471434: train_loss -0.9142 
2025-06-11 16:42:11.476986: val_loss -0.8814 
2025-06-11 16:42:11.477577: Pseudo dice [np.float32(0.8794)] 
2025-06-11 16:42:11.478152: Epoch time: 85.67 s 
2025-06-11 16:42:11.478637: Yayy! New best EMA pseudo Dice: 0.7677000164985657 
2025-06-11 16:42:13.936046:  
2025-06-11 16:42:13.936901: Epoch 21 
2025-06-11 16:42:13.937414: Current learning rate: 0.00924 
2025-06-11 16:43:39.454167: train_loss -0.9159 
2025-06-11 16:43:39.455545: val_loss -0.8799 
2025-06-11 16:43:39.456052: Pseudo dice [np.float32(0.8779)] 
2025-06-11 16:43:39.456567: Epoch time: 85.52 s 
2025-06-11 16:43:39.457089: Yayy! New best EMA pseudo Dice: 0.7786999940872192 
2025-06-11 16:43:41.879141:  
2025-06-11 16:43:41.879919: Epoch 22 
2025-06-11 16:43:41.880517: Current learning rate: 0.0092 
2025-06-11 16:45:07.376544: train_loss -0.9164 
2025-06-11 16:45:07.378101: val_loss -0.8793 
2025-06-11 16:45:07.378733: Pseudo dice [np.float32(0.8713)] 
2025-06-11 16:45:07.379431: Epoch time: 85.5 s 
2025-06-11 16:45:07.380013: Yayy! New best EMA pseudo Dice: 0.7879999876022339 
2025-06-11 16:45:09.864879:  
2025-06-11 16:45:09.865743: Epoch 23 
2025-06-11 16:45:09.866338: Current learning rate: 0.00917 
2025-06-11 16:46:35.442640: train_loss -0.9186 
2025-06-11 16:46:35.444094: val_loss -0.8671 
2025-06-11 16:46:35.444659: Pseudo dice [np.float32(0.8649)] 
2025-06-11 16:46:35.445255: Epoch time: 85.58 s 
2025-06-11 16:46:35.445741: Yayy! New best EMA pseudo Dice: 0.7957000136375427 
2025-06-11 16:46:37.863387:  
2025-06-11 16:46:37.864122: Epoch 24 
2025-06-11 16:46:37.864685: Current learning rate: 0.00913 
2025-06-11 16:48:03.451872: train_loss -0.9188 
2025-06-11 16:48:03.453474: val_loss -0.8781 
2025-06-11 16:48:03.454095: Pseudo dice [np.float32(0.8729)] 
2025-06-11 16:48:03.454722: Epoch time: 85.59 s 
2025-06-11 16:48:03.455316: Yayy! New best EMA pseudo Dice: 0.8033999800682068 
2025-06-11 16:48:05.893856:  
2025-06-11 16:48:05.894567: Epoch 25 
2025-06-11 16:48:05.895120: Current learning rate: 0.0091 
2025-06-11 16:49:31.456387: train_loss -0.9186 
2025-06-11 16:49:31.458215: val_loss -0.8782 
2025-06-11 16:49:31.458931: Pseudo dice [np.float32(0.8764)] 
2025-06-11 16:49:31.459790: Epoch time: 85.57 s 
2025-06-11 16:49:31.460498: Yayy! New best EMA pseudo Dice: 0.810699999332428 
2025-06-11 16:49:33.889177:  
2025-06-11 16:49:33.890043: Epoch 26 
2025-06-11 16:49:33.890691: Current learning rate: 0.00906 
2025-06-11 16:50:59.537773: train_loss -0.9198 
2025-06-11 16:50:59.539454: val_loss -0.8755 
2025-06-11 16:50:59.540027: Pseudo dice [np.float32(0.8702)] 
2025-06-11 16:50:59.540618: Epoch time: 85.65 s 
2025-06-11 16:50:59.541148: Yayy! New best EMA pseudo Dice: 0.8166000247001648 
2025-06-11 16:51:01.979579:  
2025-06-11 16:51:01.980408: Epoch 27 
2025-06-11 16:51:01.980982: Current learning rate: 0.00902 
2025-06-11 16:52:27.524515: train_loss -0.9215 
2025-06-11 16:52:27.525879: val_loss -0.8718 
2025-06-11 16:52:27.526788: Pseudo dice [np.float32(0.865)] 
2025-06-11 16:52:27.527401: Epoch time: 85.55 s 
2025-06-11 16:52:27.527905: Yayy! New best EMA pseudo Dice: 0.8215000033378601 
2025-06-11 16:52:29.965237:  
2025-06-11 16:52:29.966163: Epoch 28 
2025-06-11 16:52:29.966736: Current learning rate: 0.00899 
2025-06-11 16:53:55.614781: train_loss -0.9229 
2025-06-11 16:53:55.616485: val_loss -0.8784 
2025-06-11 16:53:55.617311: Pseudo dice [np.float32(0.8732)] 
2025-06-11 16:53:55.618026: Epoch time: 85.65 s 
2025-06-11 16:53:55.618653: Yayy! New best EMA pseudo Dice: 0.8266000151634216 
2025-06-11 16:53:58.062467:  
2025-06-11 16:53:58.063158: Epoch 29 
2025-06-11 16:53:58.063728: Current learning rate: 0.00895 
2025-06-11 16:55:23.562679: train_loss -0.9216 
2025-06-11 16:55:23.564352: val_loss -0.872 
2025-06-11 16:55:23.564973: Pseudo dice [np.float32(0.8699)] 
2025-06-11 16:55:23.565829: Epoch time: 85.5 s 
2025-06-11 16:55:23.566648: Yayy! New best EMA pseudo Dice: 0.8309999704360962 
2025-06-11 16:55:26.072398:  
2025-06-11 16:55:26.073164: Epoch 30 
2025-06-11 16:55:26.073657: Current learning rate: 0.00891 
2025-06-11 16:56:51.680206: train_loss -0.9216 
2025-06-11 16:56:51.681961: val_loss -0.8782 
2025-06-11 16:56:51.682755: Pseudo dice [np.float32(0.8695)] 
2025-06-11 16:56:51.683309: Epoch time: 85.61 s 
2025-06-11 16:56:51.683934: Yayy! New best EMA pseudo Dice: 0.8348000049591064 
2025-06-11 16:56:54.165088:  
2025-06-11 16:56:54.165777: Epoch 31 
2025-06-11 16:56:54.166315: Current learning rate: 0.00888 
2025-06-11 16:58:19.703577: train_loss -0.9249 
2025-06-11 16:58:19.705764: val_loss -0.8848 
2025-06-11 16:58:19.706570: Pseudo dice [np.float32(0.8803)] 
2025-06-11 16:58:19.707243: Epoch time: 85.54 s 
2025-06-11 16:58:19.707882: Yayy! New best EMA pseudo Dice: 0.8393999934196472 
2025-06-11 16:58:22.178079:  
2025-06-11 16:58:22.178861: Epoch 32 
2025-06-11 16:58:22.179513: Current learning rate: 0.00884 
2025-06-11 16:59:47.755902: train_loss -0.928 
2025-06-11 16:59:47.757727: val_loss -0.8973 
2025-06-11 16:59:47.758351: Pseudo dice [np.float32(0.8928)] 
2025-06-11 16:59:47.759228: Epoch time: 85.58 s 
2025-06-11 16:59:47.759692: Yayy! New best EMA pseudo Dice: 0.8446999788284302 
2025-06-11 16:59:50.218295:  
2025-06-11 16:59:50.218954: Epoch 33 
2025-06-11 16:59:50.219480: Current learning rate: 0.0088 
2025-06-11 17:01:15.836931: train_loss -0.9307 
2025-06-11 17:01:15.838451: val_loss -0.8981 
2025-06-11 17:01:15.838910: Pseudo dice [np.float32(0.8947)] 
2025-06-11 17:01:15.839361: Epoch time: 85.62 s 
2025-06-11 17:01:15.839811: Yayy! New best EMA pseudo Dice: 0.8496999740600586 
2025-06-11 17:01:18.310326:  
2025-06-11 17:01:18.311081: Epoch 34 
2025-06-11 17:01:18.311588: Current learning rate: 0.00877 
2025-06-11 17:02:43.905965: train_loss -0.9292 
2025-06-11 17:02:43.907650: val_loss -0.8788 
2025-06-11 17:02:43.908195: Pseudo dice [np.float32(0.8789)] 
2025-06-11 17:02:43.909126: Epoch time: 85.6 s 
2025-06-11 17:02:43.909732: Yayy! New best EMA pseudo Dice: 0.8525999784469604 
2025-06-11 17:02:46.382482:  
2025-06-11 17:02:46.383157: Epoch 35 
2025-06-11 17:02:46.383687: Current learning rate: 0.00873 
2025-06-11 17:04:11.837492: train_loss -0.9315 
2025-06-11 17:04:11.838896: val_loss -0.8957 
2025-06-11 17:04:11.839461: Pseudo dice [np.float32(0.8952)] 
2025-06-11 17:04:11.840091: Epoch time: 85.46 s 
2025-06-11 17:04:11.840890: Yayy! New best EMA pseudo Dice: 0.8568999767303467 
2025-06-11 17:04:14.304037:  
2025-06-11 17:04:14.304777: Epoch 36 
2025-06-11 17:04:14.305379: Current learning rate: 0.00869 
2025-06-11 17:05:39.807647: train_loss -0.9316 
2025-06-11 17:05:39.809088: val_loss -0.8931 
2025-06-11 17:05:39.809647: Pseudo dice [np.float32(0.8912)] 
2025-06-11 17:05:39.810212: Epoch time: 85.51 s 
2025-06-11 17:05:39.810685: Yayy! New best EMA pseudo Dice: 0.8603000044822693 
2025-06-11 17:05:42.250803:  
2025-06-11 17:05:42.251487: Epoch 37 
2025-06-11 17:05:42.251981: Current learning rate: 0.00866 
2025-06-11 17:07:07.669065: train_loss -0.9317 
2025-06-11 17:07:07.670553: val_loss -0.8942 
2025-06-11 17:07:07.671135: Pseudo dice [np.float32(0.8934)] 
2025-06-11 17:07:07.671748: Epoch time: 85.42 s 
2025-06-11 17:07:07.672353: Yayy! New best EMA pseudo Dice: 0.8636000156402588 
2025-06-11 17:07:10.188905:  
2025-06-11 17:07:10.189570: Epoch 38 
2025-06-11 17:07:10.190248: Current learning rate: 0.00862 
2025-06-11 17:08:35.644851: train_loss -0.9343 
2025-06-11 17:08:35.646317: val_loss -0.8975 
2025-06-11 17:08:35.646752: Pseudo dice [np.float32(0.9003)] 
2025-06-11 17:08:35.647236: Epoch time: 85.46 s 
2025-06-11 17:08:35.647745: Yayy! New best EMA pseudo Dice: 0.8672999739646912 
2025-06-11 17:08:38.109342:  
2025-06-11 17:08:38.110245: Epoch 39 
2025-06-11 17:08:38.110877: Current learning rate: 0.00858 
2025-06-11 17:10:03.667434: train_loss -0.9332 
2025-06-11 17:10:03.668907: val_loss -0.8953 
2025-06-11 17:10:03.669422: Pseudo dice [np.float32(0.894)] 
2025-06-11 17:10:03.670018: Epoch time: 85.56 s 
2025-06-11 17:10:03.670554: Yayy! New best EMA pseudo Dice: 0.8700000047683716 
2025-06-11 17:10:06.186652:  
2025-06-11 17:10:06.187449: Epoch 40 
2025-06-11 17:10:06.188457: Current learning rate: 0.00855 
2025-06-11 17:11:31.604513: train_loss -0.9356 
2025-06-11 17:11:31.605999: val_loss -0.8995 
2025-06-11 17:11:31.606799: Pseudo dice [np.float32(0.8947)] 
2025-06-11 17:11:31.607769: Epoch time: 85.42 s 
2025-06-11 17:11:31.608351: Yayy! New best EMA pseudo Dice: 0.8723999857902527 
2025-06-11 17:11:34.138744:  
2025-06-11 17:11:34.139567: Epoch 41 
2025-06-11 17:11:34.140315: Current learning rate: 0.00851 
2025-06-11 17:12:59.673402: train_loss -0.9345 
2025-06-11 17:12:59.675287: val_loss -0.8981 
2025-06-11 17:12:59.675952: Pseudo dice [np.float32(0.8972)] 
2025-06-11 17:12:59.676571: Epoch time: 85.54 s 
2025-06-11 17:12:59.677140: Yayy! New best EMA pseudo Dice: 0.8748999834060669 
2025-06-11 17:13:02.096920:  
2025-06-11 17:13:02.097758: Epoch 42 
2025-06-11 17:13:02.098407: Current learning rate: 0.00847 
2025-06-11 17:14:27.726572: train_loss -0.9343 
2025-06-11 17:14:27.728147: val_loss -0.8931 
2025-06-11 17:14:27.728734: Pseudo dice [np.float32(0.8905)] 
2025-06-11 17:14:27.729527: Epoch time: 85.63 s 
2025-06-11 17:14:27.730147: Yayy! New best EMA pseudo Dice: 0.8765000104904175 
2025-06-11 17:14:31.336788:  
2025-06-11 17:14:31.337605: Epoch 43 
2025-06-11 17:14:31.338201: Current learning rate: 0.00844 
2025-06-11 17:15:56.872120: train_loss -0.9361 
2025-06-11 17:15:56.873562: val_loss -0.8904 
2025-06-11 17:15:56.874112: Pseudo dice [np.float32(0.8913)] 
2025-06-11 17:15:56.874699: Epoch time: 85.54 s 
2025-06-11 17:15:56.875243: Yayy! New best EMA pseudo Dice: 0.8779000043869019 
2025-06-11 17:15:59.375419:  
2025-06-11 17:15:59.376163: Epoch 44 
2025-06-11 17:15:59.376732: Current learning rate: 0.0084 
2025-06-11 17:17:24.941456: train_loss -0.9354 
2025-06-11 17:17:24.942960: val_loss -0.8977 
2025-06-11 17:17:24.943582: Pseudo dice [np.float32(0.8919)] 
2025-06-11 17:17:24.944314: Epoch time: 85.57 s 
2025-06-11 17:17:24.944830: Yayy! New best EMA pseudo Dice: 0.8792999982833862 
2025-06-11 17:17:27.399339:  
2025-06-11 17:17:27.400202: Epoch 45 
2025-06-11 17:17:27.400747: Current learning rate: 0.00836 
2025-06-11 17:18:52.983743: train_loss -0.9368 
2025-06-11 17:18:52.985154: val_loss -0.9034 
2025-06-11 17:18:52.986014: Pseudo dice [np.float32(0.8957)] 
2025-06-11 17:18:52.986603: Epoch time: 85.59 s 
2025-06-11 17:18:52.987302: Yayy! New best EMA pseudo Dice: 0.8809999823570251 
2025-06-11 17:18:55.451870:  
2025-06-11 17:18:55.452673: Epoch 46 
2025-06-11 17:18:55.453186: Current learning rate: 0.00833 
2025-06-11 17:20:20.965236: train_loss -0.9365 
2025-06-11 17:20:20.966653: val_loss -0.9023 
2025-06-11 17:20:20.967315: Pseudo dice [np.float32(0.8965)] 
2025-06-11 17:20:20.968058: Epoch time: 85.52 s 
2025-06-11 17:20:20.968668: Yayy! New best EMA pseudo Dice: 0.8824999928474426 
2025-06-11 17:20:23.448182:  
2025-06-11 17:20:23.449023: Epoch 47 
2025-06-11 17:20:23.449573: Current learning rate: 0.00829 
2025-06-11 17:21:49.060202: train_loss -0.9363 
2025-06-11 17:21:49.061675: val_loss -0.8966 
2025-06-11 17:21:49.062246: Pseudo dice [np.float32(0.8898)] 
2025-06-11 17:21:49.062870: Epoch time: 85.61 s 
2025-06-11 17:21:49.063392: Yayy! New best EMA pseudo Dice: 0.8831999897956848 
2025-06-11 17:21:51.500767:  
2025-06-11 17:21:51.501562: Epoch 48 
2025-06-11 17:21:51.502153: Current learning rate: 0.00825 
2025-06-11 17:23:17.125963: train_loss -0.9387 
2025-06-11 17:23:17.127329: val_loss -0.8935 
2025-06-11 17:23:17.127798: Pseudo dice [np.float32(0.8952)] 
2025-06-11 17:23:17.128376: Epoch time: 85.63 s 
2025-06-11 17:23:17.128863: Yayy! New best EMA pseudo Dice: 0.8844000101089478 
2025-06-11 17:23:19.592438:  
2025-06-11 17:23:19.593208: Epoch 49 
2025-06-11 17:23:19.593842: Current learning rate: 0.00822 
2025-06-11 17:24:45.179294: train_loss -0.9381 
2025-06-11 17:24:45.181027: val_loss -0.9007 
2025-06-11 17:24:45.181637: Pseudo dice [np.float32(0.8911)] 
2025-06-11 17:24:45.182227: Epoch time: 85.59 s 
2025-06-11 17:24:46.471834: Yayy! New best EMA pseudo Dice: 0.8851000070571899 
2025-06-11 17:24:48.931364:  
2025-06-11 17:24:48.932261: Epoch 50 
2025-06-11 17:24:48.933037: Current learning rate: 0.00818 
2025-06-11 17:26:14.467723: train_loss -0.9398 
2025-06-11 17:26:14.469059: val_loss -0.8941 
2025-06-11 17:26:14.469566: Pseudo dice [np.float32(0.8938)] 
2025-06-11 17:26:14.470078: Epoch time: 85.54 s 
2025-06-11 17:26:14.470597: Yayy! New best EMA pseudo Dice: 0.8859999775886536 
2025-06-11 17:26:16.927569:  
2025-06-11 17:26:16.928386: Epoch 51 
2025-06-11 17:26:16.928928: Current learning rate: 0.00814 
2025-06-11 17:27:42.436832: train_loss -0.939 
2025-06-11 17:27:42.438374: val_loss -0.8987 
2025-06-11 17:27:42.438935: Pseudo dice [np.float32(0.8997)] 
2025-06-11 17:27:42.439447: Epoch time: 85.51 s 
2025-06-11 17:27:42.440039: Yayy! New best EMA pseudo Dice: 0.8873000144958496 
2025-06-11 17:27:44.963332:  
2025-06-11 17:27:44.964375: Epoch 52 
2025-06-11 17:27:44.965199: Current learning rate: 0.00811 
2025-06-11 17:29:10.606523: train_loss -0.9385 
2025-06-11 17:29:10.607948: val_loss -0.8956 
2025-06-11 17:29:10.608599: Pseudo dice [np.float32(0.8909)] 
2025-06-11 17:29:10.609350: Epoch time: 85.65 s 
2025-06-11 17:29:10.609924: Yayy! New best EMA pseudo Dice: 0.8877000212669373 
2025-06-11 17:29:13.061923:  
2025-06-11 17:29:13.062613: Epoch 53 
2025-06-11 17:29:13.063196: Current learning rate: 0.00807 
2025-06-11 17:30:38.715330: train_loss -0.9386 
2025-06-11 17:30:38.717411: val_loss -0.8949 
2025-06-11 17:30:38.717978: Pseudo dice [np.float32(0.8901)] 
2025-06-11 17:30:38.718518: Epoch time: 85.66 s 
2025-06-11 17:30:38.719115: Yayy! New best EMA pseudo Dice: 0.8878999948501587 
2025-06-11 17:30:41.167375:  
2025-06-11 17:30:41.168175: Epoch 54 
2025-06-11 17:30:41.168787: Current learning rate: 0.00803 
2025-06-11 17:32:06.680561: train_loss -0.9388 
2025-06-11 17:32:06.681969: val_loss -0.9028 
2025-06-11 17:32:06.682614: Pseudo dice [np.float32(0.8989)] 
2025-06-11 17:32:06.683312: Epoch time: 85.52 s 
2025-06-11 17:32:06.683928: Yayy! New best EMA pseudo Dice: 0.8889999985694885 
2025-06-11 17:32:09.074249:  
2025-06-11 17:32:09.075110: Epoch 55 
2025-06-11 17:32:09.075802: Current learning rate: 0.008 
2025-06-11 17:33:34.597082: train_loss -0.9397 
2025-06-11 17:33:34.598652: val_loss -0.8975 
2025-06-11 17:33:34.599319: Pseudo dice [np.float32(0.8916)] 
2025-06-11 17:33:34.599957: Epoch time: 85.53 s 
2025-06-11 17:33:34.600561: Yayy! New best EMA pseudo Dice: 0.8892999887466431 
2025-06-11 17:33:37.104762:  
2025-06-11 17:33:37.105444: Epoch 56 
2025-06-11 17:33:37.106231: Current learning rate: 0.00796 
2025-06-11 17:35:02.629279: train_loss -0.9404 
2025-06-11 17:35:02.630698: val_loss -0.9076 
2025-06-11 17:35:02.631179: Pseudo dice [np.float32(0.9015)] 
2025-06-11 17:35:02.631754: Epoch time: 85.53 s 
2025-06-11 17:35:02.632291: Yayy! New best EMA pseudo Dice: 0.890500009059906 
2025-06-11 17:35:05.161272:  
2025-06-11 17:35:05.161996: Epoch 57 
2025-06-11 17:35:05.162528: Current learning rate: 0.00792 
2025-06-11 17:36:30.756792: train_loss -0.9407 
2025-06-11 17:36:30.758401: val_loss -0.8974 
2025-06-11 17:36:30.759131: Pseudo dice [np.float32(0.8986)] 
2025-06-11 17:36:30.759737: Epoch time: 85.6 s 
2025-06-11 17:36:30.760368: Yayy! New best EMA pseudo Dice: 0.8913000226020813 
2025-06-11 17:36:33.260964:  
2025-06-11 17:36:33.261743: Epoch 58 
2025-06-11 17:36:33.262369: Current learning rate: 0.00789 
2025-06-11 17:37:58.684899: train_loss -0.9409 
2025-06-11 17:37:58.687179: val_loss -0.9061 
2025-06-11 17:37:58.687809: Pseudo dice [np.float32(0.9026)] 
2025-06-11 17:37:58.688397: Epoch time: 85.43 s 
2025-06-11 17:37:58.689028: Yayy! New best EMA pseudo Dice: 0.8924999833106995 
2025-06-11 17:38:01.158736:  
2025-06-11 17:38:01.159516: Epoch 59 
2025-06-11 17:38:01.160074: Current learning rate: 0.00785 
2025-06-11 17:39:26.768690: train_loss -0.9414 
2025-06-11 17:39:26.769985: val_loss -0.8978 
2025-06-11 17:39:26.770454: Pseudo dice [np.float32(0.8944)] 
2025-06-11 17:39:26.770962: Epoch time: 85.61 s 
2025-06-11 17:39:26.771450: Yayy! New best EMA pseudo Dice: 0.8927000164985657 
2025-06-11 17:39:29.205697:  
2025-06-11 17:39:29.206425: Epoch 60 
2025-06-11 17:39:29.206977: Current learning rate: 0.00781 
2025-06-11 17:40:54.725853: train_loss -0.9419 
2025-06-11 17:40:54.727353: val_loss -0.8901 
2025-06-11 17:40:54.727911: Pseudo dice [np.float32(0.8889)] 
2025-06-11 17:40:54.728487: Epoch time: 85.52 s 
2025-06-11 17:40:55.831651:  
2025-06-11 17:40:55.832892: Epoch 61 
2025-06-11 17:40:55.833457: Current learning rate: 0.00777 
2025-06-11 17:42:21.401202: train_loss -0.9414 
2025-06-11 17:42:21.402615: val_loss -0.8971 
2025-06-11 17:42:21.403130: Pseudo dice [np.float32(0.8962)] 
2025-06-11 17:42:21.403758: Epoch time: 85.57 s 
2025-06-11 17:42:21.404343: Yayy! New best EMA pseudo Dice: 0.8927000164985657 
2025-06-11 17:42:23.865268:  
2025-06-11 17:42:23.866086: Epoch 62 
2025-06-11 17:42:23.866745: Current learning rate: 0.00774 
2025-06-11 17:43:49.352798: train_loss -0.942 
2025-06-11 17:43:49.354028: val_loss -0.902 
2025-06-11 17:43:49.354994: Pseudo dice [np.float32(0.9012)] 
2025-06-11 17:43:49.355527: Epoch time: 85.49 s 
2025-06-11 17:43:49.356013: Yayy! New best EMA pseudo Dice: 0.8934999704360962 
2025-06-11 17:43:51.852090:  
2025-06-11 17:43:51.852937: Epoch 63 
2025-06-11 17:43:51.853487: Current learning rate: 0.0077 
2025-06-11 17:45:17.378251: train_loss -0.9423 
2025-06-11 17:45:17.379655: val_loss -0.9098 
2025-06-11 17:45:17.380172: Pseudo dice [np.float32(0.9066)] 
2025-06-11 17:45:17.380699: Epoch time: 85.53 s 
2025-06-11 17:45:17.381126: Yayy! New best EMA pseudo Dice: 0.8948000073432922 
2025-06-11 17:45:19.823578:  
2025-06-11 17:45:19.824262: Epoch 64 
2025-06-11 17:45:19.824783: Current learning rate: 0.00766 
2025-06-11 17:46:45.306564: train_loss -0.9427 
2025-06-11 17:46:45.307931: val_loss -0.9031 
2025-06-11 17:46:45.308469: Pseudo dice [np.float32(0.898)] 
2025-06-11 17:46:45.309035: Epoch time: 85.49 s 
2025-06-11 17:46:45.309526: Yayy! New best EMA pseudo Dice: 0.8950999975204468 
2025-06-11 17:46:47.722077:  
2025-06-11 17:46:47.722909: Epoch 65 
2025-06-11 17:46:47.723493: Current learning rate: 0.00763 
2025-06-11 17:48:13.324637: train_loss -0.9431 
2025-06-11 17:48:13.326779: val_loss -0.9062 
2025-06-11 17:48:13.327284: Pseudo dice [np.float32(0.9062)] 
2025-06-11 17:48:13.327881: Epoch time: 85.61 s 
2025-06-11 17:48:13.328425: Yayy! New best EMA pseudo Dice: 0.8962000012397766 
2025-06-11 17:48:16.003521:  
2025-06-11 17:48:16.004203: Epoch 66 
2025-06-11 17:48:16.004726: Current learning rate: 0.00759 
2025-06-11 17:49:41.650499: train_loss -0.9424 
2025-06-11 17:49:41.652250: val_loss -0.8989 
2025-06-11 17:49:41.652784: Pseudo dice [np.float32(0.8925)] 
2025-06-11 17:49:41.653380: Epoch time: 85.65 s 
2025-06-11 17:49:44.041009:  
2025-06-11 17:49:44.041691: Epoch 67 
2025-06-11 17:49:44.042336: Current learning rate: 0.00755 
2025-06-11 17:51:09.807225: train_loss -0.9428 
2025-06-11 17:51:09.808661: val_loss -0.8965 
2025-06-11 17:51:09.809309: Pseudo dice [np.float32(0.8952)] 
2025-06-11 17:51:09.809927: Epoch time: 85.77 s 
2025-06-11 17:51:10.947222:  
2025-06-11 17:51:10.948128: Epoch 68 
2025-06-11 17:51:10.948672: Current learning rate: 0.00751 
2025-06-11 17:52:36.630556: train_loss -0.9434 
2025-06-11 17:52:36.631974: val_loss -0.9017 
2025-06-11 17:52:36.632458: Pseudo dice [np.float32(0.9026)] 
2025-06-11 17:52:36.633020: Epoch time: 85.69 s 
2025-06-11 17:52:36.633535: Yayy! New best EMA pseudo Dice: 0.8964999914169312 
2025-06-11 17:52:39.150564:  
2025-06-11 17:52:39.151361: Epoch 69 
2025-06-11 17:52:39.151873: Current learning rate: 0.00748 
2025-06-11 17:54:04.939358: train_loss -0.944 
2025-06-11 17:54:04.940813: val_loss -0.8943 
2025-06-11 17:54:04.941403: Pseudo dice [np.float32(0.8948)] 
2025-06-11 17:54:04.941979: Epoch time: 85.79 s 
2025-06-11 17:54:06.098689:  
2025-06-11 17:54:06.099351: Epoch 70 
2025-06-11 17:54:06.099838: Current learning rate: 0.00744 
2025-06-11 17:55:31.793098: train_loss -0.9443 
2025-06-11 17:55:31.794790: val_loss -0.8952 
2025-06-11 17:55:31.795327: Pseudo dice [np.float32(0.8924)] 
2025-06-11 17:55:31.795820: Epoch time: 85.7 s 
2025-06-11 17:55:32.896706:  
2025-06-11 17:55:32.897429: Epoch 71 
2025-06-11 17:55:32.897944: Current learning rate: 0.0074 
2025-06-11 17:56:58.501236: train_loss -0.9435 
2025-06-11 17:56:58.502552: val_loss -0.9012 
2025-06-11 17:56:58.503021: Pseudo dice [np.float32(0.8966)] 
2025-06-11 17:56:58.503518: Epoch time: 85.61 s 
2025-06-11 17:56:59.630066:  
2025-06-11 17:56:59.630851: Epoch 72 
2025-06-11 17:56:59.631421: Current learning rate: 0.00737 
2025-06-11 17:58:25.307518: train_loss -0.9445 
2025-06-11 17:58:25.309135: val_loss -0.8928 
2025-06-11 17:58:25.309704: Pseudo dice [np.float32(0.8876)] 
2025-06-11 17:58:25.310261: Epoch time: 85.68 s 
2025-06-11 17:58:26.458314:  
2025-06-11 17:58:26.459253: Epoch 73 
2025-06-11 17:58:26.459785: Current learning rate: 0.00733 
2025-06-11 17:59:51.932648: train_loss -0.9434 
2025-06-11 17:59:51.934480: val_loss -0.8993 
2025-06-11 17:59:51.935494: Pseudo dice [np.float32(0.8949)] 
2025-06-11 17:59:51.936084: Epoch time: 85.48 s 
2025-06-11 17:59:53.053485:  
2025-06-11 17:59:53.054293: Epoch 74 
2025-06-11 17:59:53.055024: Current learning rate: 0.00729 
2025-06-11 18:01:18.632288: train_loss -0.9442 
2025-06-11 18:01:18.633666: val_loss -0.9117 
2025-06-11 18:01:18.634442: Pseudo dice [np.float32(0.906)] 
2025-06-11 18:01:18.635317: Epoch time: 85.58 s 
2025-06-11 18:01:19.743575:  
2025-06-11 18:01:19.744449: Epoch 75 
2025-06-11 18:01:19.744955: Current learning rate: 0.00725 
2025-06-11 18:02:45.391454: train_loss -0.9436 
2025-06-11 18:02:45.392875: val_loss -0.8957 
2025-06-11 18:02:45.393753: Pseudo dice [np.float32(0.8927)] 
2025-06-11 18:02:45.394379: Epoch time: 85.65 s 
2025-06-11 18:02:46.533119:  
2025-06-11 18:02:46.533875: Epoch 76 
2025-06-11 18:02:46.534399: Current learning rate: 0.00722 
2025-06-11 18:04:12.081648: train_loss -0.9443 
2025-06-11 18:04:12.083524: val_loss -0.899 
2025-06-11 18:04:12.083985: Pseudo dice [np.float32(0.8965)] 
2025-06-11 18:04:12.084544: Epoch time: 85.55 s 
2025-06-11 18:04:13.205056:  
2025-06-11 18:04:13.205803: Epoch 77 
2025-06-11 18:04:13.206373: Current learning rate: 0.00718 
2025-06-11 18:05:38.852798: train_loss -0.9445 
2025-06-11 18:05:38.854288: val_loss -0.8958 
2025-06-11 18:05:38.854881: Pseudo dice [np.float32(0.8951)] 
2025-06-11 18:05:38.855591: Epoch time: 85.65 s 
2025-06-11 18:05:39.961830:  
2025-06-11 18:05:39.962635: Epoch 78 
2025-06-11 18:05:39.963277: Current learning rate: 0.00714 
2025-06-11 18:07:05.659422: train_loss -0.9444 
2025-06-11 18:07:05.661085: val_loss -0.8956 
2025-06-11 18:07:05.661648: Pseudo dice [np.float32(0.8935)] 
2025-06-11 18:07:05.662219: Epoch time: 85.7 s 
2025-06-11 18:07:06.800370:  
2025-06-11 18:07:06.801035: Epoch 79 
2025-06-11 18:07:06.801597: Current learning rate: 0.0071 
2025-06-11 18:08:32.485197: train_loss -0.9457 
2025-06-11 18:08:32.486916: val_loss -0.904 
2025-06-11 18:08:32.487826: Pseudo dice [np.float32(0.8988)] 
2025-06-11 18:08:32.488437: Epoch time: 85.69 s 
2025-06-11 18:08:33.595749:  
2025-06-11 18:08:33.596453: Epoch 80 
2025-06-11 18:08:33.596979: Current learning rate: 0.00707 
2025-06-11 18:09:59.322986: train_loss -0.9453 
2025-06-11 18:09:59.324376: val_loss -0.8948 
2025-06-11 18:09:59.324912: Pseudo dice [np.float32(0.8915)] 
2025-06-11 18:09:59.325499: Epoch time: 85.73 s 
2025-06-11 18:10:00.454749:  
2025-06-11 18:10:00.455636: Epoch 81 
2025-06-11 18:10:00.456256: Current learning rate: 0.00703 
2025-06-11 18:11:26.119724: train_loss -0.9452 
2025-06-11 18:11:26.121103: val_loss -0.8978 
2025-06-11 18:11:26.121649: Pseudo dice [np.float32(0.8966)] 
2025-06-11 18:11:26.122362: Epoch time: 85.67 s 
2025-06-11 18:11:27.245982:  
2025-06-11 18:11:27.246727: Epoch 82 
2025-06-11 18:11:27.247255: Current learning rate: 0.00699 
2025-06-11 18:12:53.102426: train_loss -0.9445 
2025-06-11 18:12:53.103987: val_loss -0.9015 
2025-06-11 18:12:53.104581: Pseudo dice [np.float32(0.8991)] 
2025-06-11 18:12:53.105204: Epoch time: 85.86 s 
2025-06-11 18:12:54.206653:  
2025-06-11 18:12:54.207428: Epoch 83 
2025-06-11 18:12:54.207946: Current learning rate: 0.00696 
2025-06-11 18:14:19.900045: train_loss -0.9459 
2025-06-11 18:14:19.901937: val_loss -0.8895 
2025-06-11 18:14:19.902462: Pseudo dice [np.float32(0.8906)] 
2025-06-11 18:14:19.902993: Epoch time: 85.7 s 
2025-06-11 18:14:21.009179:  
2025-06-11 18:14:21.009996: Epoch 84 
2025-06-11 18:14:21.010517: Current learning rate: 0.00692 
2025-06-11 18:15:46.853311: train_loss -0.9446 
2025-06-11 18:15:46.855043: val_loss -0.8915 
2025-06-11 18:15:46.855731: Pseudo dice [np.float32(0.8876)] 
2025-06-11 18:15:46.856444: Epoch time: 85.85 s 
2025-06-11 18:15:47.989118:  
2025-06-11 18:15:47.990069: Epoch 85 
2025-06-11 18:15:47.990754: Current learning rate: 0.00688 
2025-06-11 18:17:13.699373: train_loss -0.9455 
2025-06-11 18:17:13.701253: val_loss -0.8997 
2025-06-11 18:17:13.701943: Pseudo dice [np.float32(0.8995)] 
2025-06-11 18:17:13.702800: Epoch time: 85.71 s 
2025-06-11 18:17:14.795986:  
2025-06-11 18:17:14.796641: Epoch 86 
2025-06-11 18:17:14.797606: Current learning rate: 0.00684 
2025-06-11 18:18:40.580925: train_loss -0.9462 
2025-06-11 18:18:40.582278: val_loss -0.8958 
2025-06-11 18:18:40.582823: Pseudo dice [np.float32(0.8957)] 
2025-06-11 18:18:40.583476: Epoch time: 85.79 s 
2025-06-11 18:18:41.691488:  
2025-06-11 18:18:41.692265: Epoch 87 
2025-06-11 18:18:41.692942: Current learning rate: 0.0068 
2025-06-11 18:20:07.433354: train_loss -0.9454 
2025-06-11 18:20:07.434874: val_loss -0.896 
2025-06-11 18:20:07.435394: Pseudo dice [np.float32(0.8947)] 
2025-06-11 18:20:07.435897: Epoch time: 85.74 s 
2025-06-11 18:20:08.536005:  
2025-06-11 18:20:08.536968: Epoch 88 
2025-06-11 18:20:08.537548: Current learning rate: 0.00677 
2025-06-11 18:21:34.332332: train_loss -0.9461 
2025-06-11 18:21:34.333826: val_loss -0.8956 
2025-06-11 18:21:34.334420: Pseudo dice [np.float32(0.8943)] 
2025-06-11 18:21:34.335141: Epoch time: 85.8 s 
2025-06-11 18:21:35.444652:  
2025-06-11 18:21:35.445554: Epoch 89 
2025-06-11 18:21:35.446135: Current learning rate: 0.00673 
2025-06-11 18:23:01.339847: train_loss -0.9465 
2025-06-11 18:23:01.341634: val_loss -0.9037 
2025-06-11 18:23:01.342383: Pseudo dice [np.float32(0.9009)] 
2025-06-11 18:23:01.343101: Epoch time: 85.9 s 
2025-06-11 18:23:02.508543:  
2025-06-11 18:23:02.509333: Epoch 90 
2025-06-11 18:23:02.509960: Current learning rate: 0.00669 
2025-06-11 18:24:28.401412: train_loss -0.9447 
2025-06-11 18:24:28.402915: val_loss -0.8884 
2025-06-11 18:24:28.403607: Pseudo dice [np.float32(0.8841)] 
2025-06-11 18:24:28.404218: Epoch time: 85.9 s 
2025-06-11 18:24:29.538238:  
2025-06-11 18:24:29.539148: Epoch 91 
2025-06-11 18:24:29.539745: Current learning rate: 0.00665 
2025-06-11 18:25:55.273079: train_loss -0.9459 
2025-06-11 18:25:55.274660: val_loss -0.8945 
2025-06-11 18:25:55.275398: Pseudo dice [np.float32(0.893)] 
2025-06-11 18:25:55.276091: Epoch time: 85.74 s 
2025-06-11 18:25:57.681630:  
2025-06-11 18:25:57.682364: Epoch 92 
2025-06-11 18:25:57.682906: Current learning rate: 0.00662 
2025-06-11 18:27:23.446084: train_loss -0.947 
2025-06-11 18:27:23.447631: val_loss -0.8919 
2025-06-11 18:27:23.448148: Pseudo dice [np.float32(0.8901)] 
2025-06-11 18:27:23.448710: Epoch time: 85.77 s 
2025-06-11 18:27:24.527005:  
2025-06-11 18:27:24.527846: Epoch 93 
2025-06-11 18:27:24.528363: Current learning rate: 0.00658 
2025-06-11 18:28:50.426317: train_loss -0.945 
2025-06-11 18:28:50.427755: val_loss -0.8938 
2025-06-11 18:28:50.428274: Pseudo dice [np.float32(0.8918)] 
2025-06-11 18:28:50.428849: Epoch time: 85.9 s 
2025-06-11 18:28:51.539278:  
2025-06-11 18:28:51.540134: Epoch 94 
2025-06-11 18:28:51.540781: Current learning rate: 0.00654 
2025-06-11 18:30:17.460838: train_loss -0.9472 
2025-06-11 18:30:17.462315: val_loss -0.8876 
2025-06-11 18:30:17.462815: Pseudo dice [np.float32(0.8888)] 
2025-06-11 18:30:17.463367: Epoch time: 85.92 s 
2025-06-11 18:30:18.585887:  
2025-06-11 18:30:18.586654: Epoch 95 
2025-06-11 18:30:18.587216: Current learning rate: 0.0065 
2025-06-11 18:31:44.387012: train_loss -0.9464 
2025-06-11 18:31:44.388163: val_loss -0.8958 
2025-06-11 18:31:44.388676: Pseudo dice [np.float32(0.8893)] 
2025-06-11 18:31:44.389243: Epoch time: 85.8 s 
2025-06-11 18:31:45.479006:  
2025-06-11 18:31:45.479838: Epoch 96 
2025-06-11 18:31:45.480400: Current learning rate: 0.00647 
2025-06-11 18:33:11.380710: train_loss -0.9478 
2025-06-11 18:33:11.382143: val_loss -0.8983 
2025-06-11 18:33:11.382741: Pseudo dice [np.float32(0.8963)] 
2025-06-11 18:33:11.383292: Epoch time: 85.9 s 
2025-06-11 18:33:12.505096:  
2025-06-11 18:33:12.505924: Epoch 97 
2025-06-11 18:33:12.506480: Current learning rate: 0.00643 
2025-06-11 18:34:38.310852: train_loss -0.9475 
2025-06-11 18:34:38.312460: val_loss -0.8959 
2025-06-11 18:34:38.312971: Pseudo dice [np.float32(0.8954)] 
2025-06-11 18:34:38.313489: Epoch time: 85.81 s 
2025-06-11 18:34:39.460472:  
2025-06-11 18:34:39.461298: Epoch 98 
2025-06-11 18:34:39.461819: Current learning rate: 0.00639 
2025-06-11 18:36:05.236069: train_loss -0.948 
2025-06-11 18:36:05.237597: val_loss -0.9002 
2025-06-11 18:36:05.238153: Pseudo dice [np.float32(0.9005)] 
2025-06-11 18:36:05.238832: Epoch time: 85.78 s 
2025-06-11 18:36:06.381990:  
2025-06-11 18:36:06.382732: Epoch 99 
2025-06-11 18:36:06.383228: Current learning rate: 0.00635 
2025-06-11 18:37:32.214615: train_loss -0.9475 
2025-06-11 18:37:32.216065: val_loss -0.8944 
2025-06-11 18:37:32.216483: Pseudo dice [np.float32(0.8932)] 
2025-06-11 18:37:32.217790: Epoch time: 85.84 s 
2025-06-11 18:37:34.741545:  
2025-06-11 18:37:34.742360: Epoch 100 
2025-06-11 18:37:34.742932: Current learning rate: 0.00631 
2025-06-11 18:39:00.509510: train_loss -0.9471 
2025-06-11 18:39:00.511121: val_loss -0.8944 
2025-06-11 18:39:00.511681: Pseudo dice [np.float32(0.8935)] 
2025-06-11 18:39:00.512139: Epoch time: 85.77 s 
2025-06-11 18:39:01.632779:  
2025-06-11 18:39:01.633608: Epoch 101 
2025-06-11 18:39:01.634169: Current learning rate: 0.00628 
2025-06-11 18:40:27.473773: train_loss -0.9478 
2025-06-11 18:40:27.475436: val_loss -0.8958 
2025-06-11 18:40:27.475963: Pseudo dice [np.float32(0.89)] 
2025-06-11 18:40:27.476484: Epoch time: 85.84 s 
2025-06-11 18:40:28.584414:  
2025-06-11 18:40:28.585140: Epoch 102 
2025-06-11 18:40:28.585682: Current learning rate: 0.00624 
2025-06-11 18:41:54.362959: train_loss -0.9474 
2025-06-11 18:41:54.364359: val_loss -0.8934 
2025-06-11 18:41:54.365509: Pseudo dice [np.float32(0.8934)] 
2025-06-11 18:41:54.366349: Epoch time: 85.78 s 
2025-06-11 18:41:55.490223:  
2025-06-11 18:41:55.491088: Epoch 103 
2025-06-11 18:41:55.491671: Current learning rate: 0.0062 
2025-06-11 18:43:21.302681: train_loss -0.9485 
2025-06-11 18:43:21.304057: val_loss -0.9059 
2025-06-11 18:43:21.304944: Pseudo dice [np.float32(0.9026)] 
2025-06-11 18:43:21.305556: Epoch time: 85.82 s 
2025-06-11 18:43:22.493785:  
2025-06-11 18:43:22.494582: Epoch 104 
2025-06-11 18:43:22.495205: Current learning rate: 0.00616 
2025-06-11 18:44:48.116339: train_loss -0.949 
2025-06-11 18:44:48.117939: val_loss -0.8929 
2025-06-11 18:44:48.118588: Pseudo dice [np.float32(0.8876)] 
2025-06-11 18:44:48.119289: Epoch time: 85.63 s 
2025-06-11 18:44:49.267586:  
2025-06-11 18:44:49.268453: Epoch 105 
2025-06-11 18:44:49.269052: Current learning rate: 0.00612 
2025-06-11 18:46:15.030332: train_loss -0.9468 
2025-06-11 18:46:15.031817: val_loss -0.8985 
2025-06-11 18:46:15.032348: Pseudo dice [np.float32(0.8946)] 
2025-06-11 18:46:15.032965: Epoch time: 85.77 s 
2025-06-11 18:46:16.160868:  
2025-06-11 18:46:16.161624: Epoch 106 
2025-06-11 18:46:16.162134: Current learning rate: 0.00609 
2025-06-11 18:47:41.927973: train_loss -0.9479 
2025-06-11 18:47:41.929295: val_loss -0.8947 
2025-06-11 18:47:41.929848: Pseudo dice [np.float32(0.8916)] 
2025-06-11 18:47:41.930381: Epoch time: 85.77 s 
2025-06-11 18:47:43.019042:  
2025-06-11 18:47:43.020051: Epoch 107 
2025-06-11 18:47:43.020545: Current learning rate: 0.00605 
2025-06-11 18:49:08.834256: train_loss -0.9476 
2025-06-11 18:49:08.835836: val_loss -0.8988 
2025-06-11 18:49:08.836500: Pseudo dice [np.float32(0.8964)] 
2025-06-11 18:49:08.837152: Epoch time: 85.82 s 
2025-06-11 18:49:09.983245:  
2025-06-11 18:49:09.983878: Epoch 108 
2025-06-11 18:49:09.984425: Current learning rate: 0.00601 
2025-06-11 18:50:35.848419: train_loss -0.9496 
2025-06-11 18:50:35.850049: val_loss -0.8975 
2025-06-11 18:50:35.850593: Pseudo dice [np.float32(0.8912)] 
2025-06-11 18:50:35.851127: Epoch time: 85.87 s 
2025-06-11 18:50:37.041856:  
2025-06-11 18:50:37.042653: Epoch 109 
2025-06-11 18:50:37.043208: Current learning rate: 0.00597 
2025-06-11 18:52:02.731196: train_loss -0.9479 
2025-06-11 18:52:02.732799: val_loss -0.8987 
2025-06-11 18:52:02.733300: Pseudo dice [np.float32(0.8914)] 
2025-06-11 18:52:02.733973: Epoch time: 85.69 s 
2025-06-11 18:52:03.831010:  
2025-06-11 18:52:03.832011: Epoch 110 
2025-06-11 18:52:03.832546: Current learning rate: 0.00593 
2025-06-11 18:53:29.609852: train_loss -0.9494 
2025-06-11 18:53:29.611084: val_loss -0.8984 
2025-06-11 18:53:29.611597: Pseudo dice [np.float32(0.8957)] 
2025-06-11 18:53:29.612108: Epoch time: 85.78 s 
2025-06-11 18:53:30.710745:  
2025-06-11 18:53:30.711539: Epoch 111 
2025-06-11 18:53:30.712064: Current learning rate: 0.0059 
2025-06-11 18:54:56.343811: train_loss -0.9496 
2025-06-11 18:54:56.345355: val_loss -0.8906 
2025-06-11 18:54:56.345856: Pseudo dice [np.float32(0.8883)] 
2025-06-11 18:54:56.346337: Epoch time: 85.64 s 
2025-06-11 18:54:57.474726:  
2025-06-11 18:54:57.475640: Epoch 112 
2025-06-11 18:54:57.476294: Current learning rate: 0.00586 
2025-06-11 18:56:23.153697: train_loss -0.9494 
2025-06-11 18:56:23.155171: val_loss -0.8921 
2025-06-11 18:56:23.155788: Pseudo dice [np.float32(0.8924)] 
2025-06-11 18:56:23.156454: Epoch time: 85.68 s 
2025-06-11 18:56:24.254852:  
2025-06-11 18:56:24.255477: Epoch 113 
2025-06-11 18:56:24.255932: Current learning rate: 0.00582 
2025-06-11 18:57:50.063816: train_loss -0.9487 
2025-06-11 18:57:50.065434: val_loss -0.9021 
2025-06-11 18:57:50.065998: Pseudo dice [np.float32(0.9008)] 
2025-06-11 18:57:50.066599: Epoch time: 85.81 s 
2025-06-11 18:57:51.222580:  
2025-06-11 18:57:51.223283: Epoch 114 
2025-06-11 18:57:51.223949: Current learning rate: 0.00578 
2025-06-11 18:59:16.982613: train_loss -0.9484 
2025-06-11 18:59:16.984657: val_loss -0.8938 
2025-06-11 18:59:16.985469: Pseudo dice [np.float32(0.8928)] 
2025-06-11 18:59:16.986382: Epoch time: 85.76 s 
2025-06-11 18:59:18.076395:  
2025-06-11 18:59:18.077217: Epoch 115 
2025-06-11 18:59:18.077789: Current learning rate: 0.00574 
2025-06-11 19:00:43.776491: train_loss -0.9496 
2025-06-11 19:00:43.778049: val_loss -0.8882 
2025-06-11 19:00:43.778610: Pseudo dice [np.float32(0.8868)] 
2025-06-11 19:00:43.779449: Epoch time: 85.7 s 
2025-06-11 19:00:44.910522:  
2025-06-11 19:00:44.911195: Epoch 116 
2025-06-11 19:00:44.911907: Current learning rate: 0.0057 
2025-06-11 19:02:10.628632: train_loss -0.9499 
2025-06-11 19:02:10.630224: val_loss -0.9018 
2025-06-11 19:02:10.630807: Pseudo dice [np.float32(0.8993)] 
2025-06-11 19:02:10.631381: Epoch time: 85.72 s 
2025-06-11 19:02:11.776011:  
2025-06-11 19:02:11.776925: Epoch 117 
2025-06-11 19:02:11.777517: Current learning rate: 0.00567 
2025-06-11 19:03:37.525386: train_loss -0.9504 
2025-06-11 19:03:37.526713: val_loss -0.8947 
2025-06-11 19:03:37.527267: Pseudo dice [np.float32(0.8924)] 
2025-06-11 19:03:37.527758: Epoch time: 85.75 s 
2025-06-11 19:03:38.634199:  
2025-06-11 19:03:38.634827: Epoch 118 
2025-06-11 19:03:38.635399: Current learning rate: 0.00563 
2025-06-11 19:05:05.586839: train_loss -0.9483 
2025-06-11 19:05:05.588216: val_loss -0.8948 
2025-06-11 19:05:05.588765: Pseudo dice [np.float32(0.8906)] 
2025-06-11 19:05:05.589368: Epoch time: 86.96 s 
2025-06-11 19:05:06.730709:  
2025-06-11 19:05:06.731897: Epoch 119 
2025-06-11 19:05:06.732512: Current learning rate: 0.00559 
2025-06-11 19:06:32.560183: train_loss -0.9497 
2025-06-11 19:06:32.562141: val_loss -0.8961 
2025-06-11 19:06:32.562767: Pseudo dice [np.float32(0.8902)] 
2025-06-11 19:06:32.563396: Epoch time: 85.83 s 
2025-06-11 19:06:33.683971:  
2025-06-11 19:06:33.684806: Epoch 120 
2025-06-11 19:06:33.685350: Current learning rate: 0.00555 
2025-06-11 19:07:59.532279: train_loss -0.95 
2025-06-11 19:07:59.533917: val_loss -0.893 
2025-06-11 19:07:59.534612: Pseudo dice [np.float32(0.892)] 
2025-06-11 19:07:59.535325: Epoch time: 85.85 s 
2025-06-11 19:08:00.672795:  
2025-06-11 19:08:00.673512: Epoch 121 
2025-06-11 19:08:00.674037: Current learning rate: 0.00551 
2025-06-11 19:09:26.500171: train_loss -0.9485 
2025-06-11 19:09:26.501552: val_loss -0.8968 
2025-06-11 19:09:26.502148: Pseudo dice [np.float32(0.895)] 
2025-06-11 19:09:26.503003: Epoch time: 85.83 s 
2025-06-11 19:09:27.640912:  
2025-06-11 19:09:27.641796: Epoch 122 
2025-06-11 19:09:27.642437: Current learning rate: 0.00547 
2025-06-11 19:10:53.563780: train_loss -0.9493 
2025-06-11 19:10:53.565328: val_loss -0.8948 
2025-06-11 19:10:53.566103: Pseudo dice [np.float32(0.8931)] 
2025-06-11 19:10:53.566655: Epoch time: 85.93 s 
2025-06-11 19:10:54.705579:  
2025-06-11 19:10:54.706543: Epoch 123 
2025-06-11 19:10:54.707112: Current learning rate: 0.00544 
2025-06-11 19:12:20.471041: train_loss -0.9485 
2025-06-11 19:12:20.472544: val_loss -0.9045 
2025-06-11 19:12:20.473008: Pseudo dice [np.float32(0.9028)] 
2025-06-11 19:12:20.473478: Epoch time: 85.77 s 
2025-06-11 19:12:21.575494:  
2025-06-11 19:12:21.576295: Epoch 124 
2025-06-11 19:12:21.576812: Current learning rate: 0.0054 
2025-06-11 19:13:47.420657: train_loss -0.9504 
2025-06-11 19:13:47.422098: val_loss -0.8972 
2025-06-11 19:13:47.422774: Pseudo dice [np.float32(0.8937)] 
2025-06-11 19:13:47.423512: Epoch time: 85.85 s 
2025-06-11 19:13:48.575273:  
2025-06-11 19:13:48.576198: Epoch 125 
2025-06-11 19:13:48.576808: Current learning rate: 0.00536 
2025-06-11 19:15:14.394694: train_loss -0.9482 
2025-06-11 19:15:14.395998: val_loss -0.8998 
2025-06-11 19:15:14.396709: Pseudo dice [np.float32(0.8965)] 
2025-06-11 19:15:14.397297: Epoch time: 85.82 s 
2025-06-11 19:15:15.501085:  
2025-06-11 19:15:15.501918: Epoch 126 
2025-06-11 19:15:15.502461: Current learning rate: 0.00532 
2025-06-11 19:16:41.366513: train_loss -0.949 
2025-06-11 19:16:41.368108: val_loss -0.8938 
2025-06-11 19:16:41.368875: Pseudo dice [np.float32(0.8901)] 
2025-06-11 19:16:41.369691: Epoch time: 85.87 s 
2025-06-11 19:16:42.493590:  
2025-06-11 19:16:42.494381: Epoch 127 
2025-06-11 19:16:42.494971: Current learning rate: 0.00528 
2025-06-11 19:18:08.316731: train_loss -0.9501 
2025-06-11 19:18:08.318047: val_loss -0.8981 
2025-06-11 19:18:08.318529: Pseudo dice [np.float32(0.896)] 
2025-06-11 19:18:08.319384: Epoch time: 85.83 s 
2025-06-11 19:18:09.469509:  
2025-06-11 19:18:09.470317: Epoch 128 
2025-06-11 19:18:09.470787: Current learning rate: 0.00524 
2025-06-11 19:19:35.324495: train_loss -0.9502 
2025-06-11 19:19:35.326401: val_loss -0.8969 
2025-06-11 19:19:35.326973: Pseudo dice [np.float32(0.8954)] 
2025-06-11 19:19:35.327604: Epoch time: 85.86 s 
2025-06-11 19:19:36.482362:  
2025-06-11 19:19:36.483114: Epoch 129 
2025-06-11 19:19:36.483638: Current learning rate: 0.0052 
2025-06-11 19:21:02.328409: train_loss -0.951 
2025-06-11 19:21:02.335285: val_loss -0.8973 
2025-06-11 19:21:02.336709: Pseudo dice [np.float32(0.8891)] 
2025-06-11 19:21:02.338577: Epoch time: 85.85 s 
2025-06-11 19:21:03.503145:  
2025-06-11 19:21:03.504190: Epoch 130 
2025-06-11 19:21:03.504886: Current learning rate: 0.00517 
2025-06-11 19:22:29.411273: train_loss -0.9512 
2025-06-11 19:22:29.412773: val_loss -0.8945 
2025-06-11 19:22:29.413285: Pseudo dice [np.float32(0.8881)] 
2025-06-11 19:22:29.413798: Epoch time: 85.91 s 
2025-06-11 19:22:30.553163:  
2025-06-11 19:22:30.553955: Epoch 131 
2025-06-11 19:22:30.554589: Current learning rate: 0.00513 
2025-06-11 19:23:56.363345: train_loss -0.9512 
2025-06-11 19:23:56.364924: val_loss -0.894 
2025-06-11 19:23:56.365449: Pseudo dice [np.float32(0.891)] 
2025-06-11 19:23:56.365947: Epoch time: 85.81 s 
2025-06-11 19:23:57.485032:  
2025-06-11 19:23:57.485857: Epoch 132 
2025-06-11 19:23:57.486409: Current learning rate: 0.00509 
2025-06-11 19:25:23.410989: train_loss -0.9509 
2025-06-11 19:25:23.415392: val_loss -0.8942 
2025-06-11 19:25:23.416655: Pseudo dice [np.float32(0.8901)] 
2025-06-11 19:25:23.418273: Epoch time: 85.93 s 
2025-06-11 19:25:24.512122:  
2025-06-11 19:25:24.513484: Epoch 133 
2025-06-11 19:25:24.514324: Current learning rate: 0.00505 
2025-06-11 19:26:50.317378: train_loss -0.9509 
2025-06-11 19:26:50.318799: val_loss -0.8922 
2025-06-11 19:26:50.319424: Pseudo dice [np.float32(0.891)] 
2025-06-11 19:26:50.320168: Epoch time: 85.81 s 
2025-06-11 19:26:51.475685:  
2025-06-11 19:26:51.476543: Epoch 134 
2025-06-11 19:26:51.477354: Current learning rate: 0.00501 
2025-06-11 19:28:17.301790: train_loss -0.9506 
2025-06-11 19:28:17.303437: val_loss -0.8934 
2025-06-11 19:28:17.304165: Pseudo dice [np.float32(0.8899)] 
2025-06-11 19:28:17.305001: Epoch time: 85.83 s 
2025-06-11 19:28:18.476479:  
2025-06-11 19:28:18.477122: Epoch 135 
2025-06-11 19:28:18.477650: Current learning rate: 0.00497 
2025-06-11 19:29:44.341209: train_loss -0.951 
2025-06-11 19:29:44.342574: val_loss -0.8985 
2025-06-11 19:29:44.343063: Pseudo dice [np.float32(0.8953)] 
2025-06-11 19:29:44.343514: Epoch time: 85.87 s 
2025-06-11 19:29:45.517958:  
2025-06-11 19:29:45.518837: Epoch 136 
2025-06-11 19:29:45.519468: Current learning rate: 0.00493 
2025-06-11 19:31:11.344742: train_loss -0.9506 
2025-06-11 19:31:11.346188: val_loss -0.8927 
2025-06-11 19:31:11.346875: Pseudo dice [np.float32(0.887)] 
2025-06-11 19:31:11.347500: Epoch time: 85.83 s 
2025-06-11 19:31:12.470980:  
2025-06-11 19:31:12.471723: Epoch 137 
2025-06-11 19:31:12.472310: Current learning rate: 0.00489 
2025-06-11 19:32:38.263892: train_loss -0.9511 
2025-06-11 19:32:38.265606: val_loss -0.8985 
2025-06-11 19:32:38.266205: Pseudo dice [np.float32(0.8996)] 
2025-06-11 19:32:38.266975: Epoch time: 85.8 s 
2025-06-11 19:32:39.407706:  
2025-06-11 19:32:39.408565: Epoch 138 
2025-06-11 19:32:39.409132: Current learning rate: 0.00485 
2025-06-11 19:34:05.191035: train_loss -0.9522 
2025-06-11 19:34:05.193218: val_loss -0.891 
2025-06-11 19:34:05.194282: Pseudo dice [np.float32(0.8901)] 
2025-06-11 19:34:05.195157: Epoch time: 85.79 s 
2025-06-11 19:34:06.320226:  
2025-06-11 19:34:06.321438: Epoch 139 
2025-06-11 19:34:06.322002: Current learning rate: 0.00482 
2025-06-11 19:35:32.029931: train_loss -0.9511 
2025-06-11 19:35:32.031439: val_loss -0.8924 
2025-06-11 19:35:32.031995: Pseudo dice [np.float32(0.8917)] 
2025-06-11 19:35:32.032568: Epoch time: 85.71 s 
2025-06-11 19:35:33.156169:  
2025-06-11 19:35:33.156970: Epoch 140 
2025-06-11 19:35:33.157588: Current learning rate: 0.00478 
2025-06-11 19:36:58.937765: train_loss -0.9505 
2025-06-11 19:36:58.939250: val_loss -0.8973 
2025-06-11 19:36:58.940015: Pseudo dice [np.float32(0.8954)] 
2025-06-11 19:36:58.940661: Epoch time: 85.78 s 
2025-06-11 19:37:00.106682:  
2025-06-11 19:37:00.107368: Epoch 141 
2025-06-11 19:37:00.107950: Current learning rate: 0.00474 
2025-06-11 19:38:25.808939: train_loss -0.9527 
2025-06-11 19:38:25.810717: val_loss -0.894 
2025-06-11 19:38:25.811314: Pseudo dice [np.float32(0.8905)] 
2025-06-11 19:38:25.811969: Epoch time: 85.71 s 
2025-06-11 19:38:26.944512:  
2025-06-11 19:38:26.945376: Epoch 142 
2025-06-11 19:38:26.945931: Current learning rate: 0.0047 
2025-06-11 19:39:52.568845: train_loss -0.952 
2025-06-11 19:39:52.571696: val_loss -0.8976 
2025-06-11 19:39:52.572312: Pseudo dice [np.float32(0.8943)] 
2025-06-11 19:39:52.572900: Epoch time: 85.63 s 
2025-06-11 19:39:53.665162:  
2025-06-11 19:39:53.665879: Epoch 143 
2025-06-11 19:39:53.666399: Current learning rate: 0.00466 
2025-06-11 19:41:19.439745: train_loss -0.9508 
2025-06-11 19:41:19.441444: val_loss -0.8974 
2025-06-11 19:41:19.442142: Pseudo dice [np.float32(0.8919)] 
2025-06-11 19:41:19.442966: Epoch time: 85.78 s 
2025-06-11 19:41:21.908788:  
2025-06-11 19:41:21.909552: Epoch 144 
2025-06-11 19:41:21.910141: Current learning rate: 0.00462 
2025-06-11 19:42:47.584123: train_loss -0.9524 
2025-06-11 19:42:47.585648: val_loss -0.9002 
2025-06-11 19:42:47.586167: Pseudo dice [np.float32(0.899)] 
2025-06-11 19:42:47.586874: Epoch time: 85.68 s 
2025-06-11 19:42:48.761248:  
2025-06-11 19:42:48.762111: Epoch 145 
2025-06-11 19:42:48.762853: Current learning rate: 0.00458 
2025-06-11 19:44:14.510625: train_loss -0.9526 
2025-06-11 19:44:14.512129: val_loss -0.891 
2025-06-11 19:44:14.512632: Pseudo dice [np.float32(0.8902)] 
2025-06-11 19:44:14.513243: Epoch time: 85.75 s 
2025-06-11 19:44:15.654334:  
2025-06-11 19:44:15.655239: Epoch 146 
2025-06-11 19:44:15.656049: Current learning rate: 0.00454 
2025-06-11 19:45:41.461215: train_loss -0.9511 
2025-06-11 19:45:41.462692: val_loss -0.8904 
2025-06-11 19:45:41.463295: Pseudo dice [np.float32(0.8885)] 
2025-06-11 19:45:41.463895: Epoch time: 85.81 s 
2025-06-11 19:45:42.611884:  
2025-06-11 19:45:42.612683: Epoch 147 
2025-06-11 19:45:42.613218: Current learning rate: 0.0045 
2025-06-11 19:47:08.368178: train_loss -0.9519 
2025-06-11 19:47:08.369660: val_loss -0.8993 
2025-06-11 19:47:08.370136: Pseudo dice [np.float32(0.8945)] 
2025-06-11 19:47:08.370738: Epoch time: 85.76 s 
2025-06-11 19:47:09.499246:  
2025-06-11 19:47:09.500116: Epoch 148 
2025-06-11 19:47:09.500706: Current learning rate: 0.00446 
2025-06-11 19:48:35.405983: train_loss -0.9519 
2025-06-11 19:48:35.407242: val_loss -0.9005 
2025-06-11 19:48:35.407832: Pseudo dice [np.float32(0.8968)] 
2025-06-11 19:48:35.408377: Epoch time: 85.91 s 
2025-06-11 19:48:36.526248:  
2025-06-11 19:48:36.527097: Epoch 149 
2025-06-11 19:48:36.527677: Current learning rate: 0.00442 
2025-06-11 19:50:02.379557: train_loss -0.9516 
2025-06-11 19:50:02.381129: val_loss -0.8977 
2025-06-11 19:50:02.382030: Pseudo dice [np.float32(0.8906)] 
2025-06-11 19:50:02.382837: Epoch time: 85.86 s 
2025-06-11 19:50:04.920496:  
2025-06-11 19:50:04.921252: Epoch 150 
2025-06-11 19:50:04.921767: Current learning rate: 0.00438 
2025-06-11 19:51:30.588603: train_loss -0.9519 
2025-06-11 19:51:30.589983: val_loss -0.8994 
2025-06-11 19:51:30.590542: Pseudo dice [np.float32(0.8945)] 
2025-06-11 19:51:30.591201: Epoch time: 85.67 s 
2025-06-11 19:51:31.743495:  
2025-06-11 19:51:31.744275: Epoch 151 
2025-06-11 19:51:31.744906: Current learning rate: 0.00434 
2025-06-11 19:52:57.423211: train_loss -0.9515 
2025-06-11 19:52:57.424970: val_loss -0.9026 
2025-06-11 19:52:57.425711: Pseudo dice [np.float32(0.8996)] 
2025-06-11 19:52:57.426396: Epoch time: 85.68 s 
2025-06-11 19:52:58.590136:  
2025-06-11 19:52:58.591005: Epoch 152 
2025-06-11 19:52:58.591507: Current learning rate: 0.0043 
2025-06-11 19:54:24.441736: train_loss -0.9528 
2025-06-11 19:54:24.443485: val_loss -0.8957 
2025-06-11 19:54:24.444022: Pseudo dice [np.float32(0.8918)] 
2025-06-11 19:54:24.445014: Epoch time: 85.85 s 
2025-06-11 19:54:25.588589:  
2025-06-11 19:54:25.589310: Epoch 153 
2025-06-11 19:54:25.589842: Current learning rate: 0.00427 
2025-06-11 19:55:51.350153: train_loss -0.9521 
2025-06-11 19:55:51.351575: val_loss -0.8936 
2025-06-11 19:55:51.352062: Pseudo dice [np.float32(0.8916)] 
2025-06-11 19:55:51.352641: Epoch time: 85.76 s 
2025-06-11 19:55:52.474113:  
2025-06-11 19:55:52.474936: Epoch 154 
2025-06-11 19:55:52.475410: Current learning rate: 0.00423 
2025-06-11 19:57:18.301569: train_loss -0.9511 
2025-06-11 19:57:18.303304: val_loss -0.8952 
2025-06-11 19:57:18.303942: Pseudo dice [np.float32(0.893)] 
2025-06-11 19:57:18.304727: Epoch time: 85.83 s 
2025-06-11 19:57:19.462154:  
2025-06-11 19:57:19.463029: Epoch 155 
2025-06-11 19:57:19.463596: Current learning rate: 0.00419 
2025-06-11 19:58:45.281900: train_loss -0.953 
2025-06-11 19:58:45.283642: val_loss -0.8943 
2025-06-11 19:58:45.284484: Pseudo dice [np.float32(0.8927)] 
2025-06-11 19:58:45.285073: Epoch time: 85.82 s 
2025-06-11 19:58:46.486577:  
2025-06-11 19:58:46.487410: Epoch 156 
2025-06-11 19:58:46.488046: Current learning rate: 0.00415 
2025-06-11 20:00:12.326433: train_loss -0.9523 
2025-06-11 20:00:12.327918: val_loss -0.8979 
2025-06-11 20:00:12.328512: Pseudo dice [np.float32(0.8948)] 
2025-06-11 20:00:12.329171: Epoch time: 85.84 s 
2025-06-11 20:00:13.506175:  
2025-06-11 20:00:13.507064: Epoch 157 
2025-06-11 20:00:13.507673: Current learning rate: 0.00411 
2025-06-11 20:01:39.314854: train_loss -0.9529 
2025-06-11 20:01:39.316256: val_loss -0.8931 
2025-06-11 20:01:39.316815: Pseudo dice [np.float32(0.8917)] 
2025-06-11 20:01:39.317511: Epoch time: 85.81 s 
2025-06-11 20:01:40.468537:  
2025-06-11 20:01:40.469463: Epoch 158 
2025-06-11 20:01:40.470315: Current learning rate: 0.00407 
2025-06-11 20:03:06.261552: train_loss -0.9516 
2025-06-11 20:03:06.263281: val_loss -0.8978 
2025-06-11 20:03:06.263760: Pseudo dice [np.float32(0.8962)] 
2025-06-11 20:03:06.264242: Epoch time: 85.8 s 
2025-06-11 20:03:07.403819:  
2025-06-11 20:03:07.405190: Epoch 159 
2025-06-11 20:03:07.405867: Current learning rate: 0.00403 
2025-06-11 20:04:33.100988: train_loss -0.953 
2025-06-11 20:04:33.102324: val_loss -0.8983 
2025-06-11 20:04:33.102883: Pseudo dice [np.float32(0.8931)] 
2025-06-11 20:04:33.103412: Epoch time: 85.7 s 
2025-06-11 20:04:34.220026:  
2025-06-11 20:04:34.220680: Epoch 160 
2025-06-11 20:04:34.221215: Current learning rate: 0.00399 
2025-06-11 20:05:59.854405: train_loss -0.9535 
2025-06-11 20:05:59.855809: val_loss -0.901 
2025-06-11 20:05:59.856403: Pseudo dice [np.float32(0.8954)] 
2025-06-11 20:05:59.857003: Epoch time: 85.64 s 
2025-06-11 20:06:00.987391:  
2025-06-11 20:06:00.988227: Epoch 161 
2025-06-11 20:06:00.988985: Current learning rate: 0.00395 
2025-06-11 20:07:26.709757: train_loss -0.9533 
2025-06-11 20:07:26.711383: val_loss -0.8961 
2025-06-11 20:07:26.711907: Pseudo dice [np.float32(0.8933)] 
2025-06-11 20:07:26.712371: Epoch time: 85.73 s 
2025-06-11 20:07:27.854442:  
2025-06-11 20:07:27.855057: Epoch 162 
2025-06-11 20:07:27.855736: Current learning rate: 0.00391 
2025-06-11 20:08:53.519087: train_loss -0.9534 
2025-06-11 20:08:53.520490: val_loss -0.8943 
2025-06-11 20:08:53.520981: Pseudo dice [np.float32(0.8938)] 
2025-06-11 20:08:53.521516: Epoch time: 85.67 s 
2025-06-11 20:08:54.633794:  
2025-06-11 20:08:54.634570: Epoch 163 
2025-06-11 20:08:54.635142: Current learning rate: 0.00387 
2025-06-11 20:10:20.302754: train_loss -0.9543 
2025-06-11 20:10:20.304395: val_loss -0.8986 
2025-06-11 20:10:20.305055: Pseudo dice [np.float32(0.8937)] 
2025-06-11 20:10:20.305869: Epoch time: 85.67 s 
2025-06-11 20:10:21.450590:  
2025-06-11 20:10:21.451400: Epoch 164 
2025-06-11 20:10:21.451958: Current learning rate: 0.00383 
2025-06-11 20:11:47.085640: train_loss -0.954 
2025-06-11 20:11:47.087168: val_loss -0.8991 
2025-06-11 20:11:47.088022: Pseudo dice [np.float32(0.8953)] 
2025-06-11 20:11:47.088789: Epoch time: 85.64 s 
2025-06-11 20:11:48.247652:  
2025-06-11 20:11:48.248342: Epoch 165 
2025-06-11 20:11:48.248967: Current learning rate: 0.00379 
2025-06-11 20:13:13.951090: train_loss -0.9526 
2025-06-11 20:13:13.952787: val_loss -0.8957 
2025-06-11 20:13:13.953334: Pseudo dice [np.float32(0.8891)] 
2025-06-11 20:13:13.954104: Epoch time: 85.71 s 
2025-06-11 20:13:15.072618:  
2025-06-11 20:13:15.073503: Epoch 166 
2025-06-11 20:13:15.074091: Current learning rate: 0.00375 
2025-06-11 20:14:40.800313: train_loss -0.9534 
2025-06-11 20:14:40.802221: val_loss -0.8951 
2025-06-11 20:14:40.802982: Pseudo dice [np.float32(0.8884)] 
2025-06-11 20:14:40.803780: Epoch time: 85.73 s 
2025-06-11 20:14:41.930830:  
2025-06-11 20:14:41.931809: Epoch 167 
2025-06-11 20:14:41.932393: Current learning rate: 0.00371 
2025-06-11 20:16:07.589097: train_loss -0.9544 
2025-06-11 20:16:07.590539: val_loss -0.8948 
2025-06-11 20:16:07.591100: Pseudo dice [np.float32(0.8896)] 
2025-06-11 20:16:07.591911: Epoch time: 85.66 s 
2025-06-11 20:16:08.707585:  
2025-06-11 20:16:08.708433: Epoch 168 
2025-06-11 20:16:08.709044: Current learning rate: 0.00367 
2025-06-11 20:17:35.535904: train_loss -0.9536 
2025-06-11 20:17:35.537350: val_loss -0.8972 
2025-06-11 20:17:35.537884: Pseudo dice [np.float32(0.8916)] 
2025-06-11 20:17:35.538507: Epoch time: 86.83 s 
2025-06-11 20:17:36.699691:  
2025-06-11 20:17:36.700654: Epoch 169 
2025-06-11 20:17:36.701215: Current learning rate: 0.00363 
2025-06-11 20:19:02.484111: train_loss -0.9543 
2025-06-11 20:19:02.485354: val_loss -0.9 
2025-06-11 20:19:02.485840: Pseudo dice [np.float32(0.8968)] 
2025-06-11 20:19:02.486296: Epoch time: 85.79 s 
2025-06-11 20:19:03.611509:  
2025-06-11 20:19:03.612278: Epoch 170 
2025-06-11 20:19:03.612823: Current learning rate: 0.00359 
2025-06-11 20:20:29.341043: train_loss -0.9546 
2025-06-11 20:20:29.342419: val_loss -0.9011 
2025-06-11 20:20:29.342991: Pseudo dice [np.float32(0.8945)] 
2025-06-11 20:20:29.343523: Epoch time: 85.73 s 
2025-06-11 20:20:30.478580:  
2025-06-11 20:20:30.479508: Epoch 171 
2025-06-11 20:20:30.480218: Current learning rate: 0.00355 
2025-06-11 20:21:56.139537: train_loss -0.9547 
2025-06-11 20:21:56.140776: val_loss -0.9036 
2025-06-11 20:21:56.141306: Pseudo dice [np.float32(0.8966)] 
2025-06-11 20:21:56.141795: Epoch time: 85.66 s 
2025-06-11 20:21:57.294113:  
2025-06-11 20:21:57.295103: Epoch 172 
2025-06-11 20:21:57.295731: Current learning rate: 0.00351 
2025-06-11 20:23:22.983691: train_loss -0.9539 
2025-06-11 20:23:22.985374: val_loss -0.8961 
2025-06-11 20:23:22.986043: Pseudo dice [np.float32(0.8918)] 
2025-06-11 20:23:22.986730: Epoch time: 85.69 s 
2025-06-11 20:23:24.108701:  
2025-06-11 20:23:24.109643: Epoch 173 
2025-06-11 20:23:24.110294: Current learning rate: 0.00346 
2025-06-11 20:24:49.830889: train_loss -0.9537 
2025-06-11 20:24:49.832295: val_loss -0.8979 
2025-06-11 20:24:49.832902: Pseudo dice [np.float32(0.8936)] 
2025-06-11 20:24:49.833396: Epoch time: 85.73 s 
2025-06-11 20:24:50.957459:  
2025-06-11 20:24:50.958302: Epoch 174 
2025-06-11 20:24:50.958839: Current learning rate: 0.00342 
2025-06-11 20:26:16.620378: train_loss -0.955 
2025-06-11 20:26:16.622126: val_loss -0.8953 
2025-06-11 20:26:16.622925: Pseudo dice [np.float32(0.8901)] 
2025-06-11 20:26:16.623565: Epoch time: 85.67 s 
2025-06-11 20:26:17.789978:  
2025-06-11 20:26:17.790649: Epoch 175 
2025-06-11 20:26:17.791169: Current learning rate: 0.00338 
2025-06-11 20:27:43.443949: train_loss -0.9531 
2025-06-11 20:27:43.445746: val_loss -0.897 
2025-06-11 20:27:43.446339: Pseudo dice [np.float32(0.8916)] 
2025-06-11 20:27:43.447028: Epoch time: 85.66 s 
2025-06-11 20:27:44.609925:  
2025-06-11 20:27:44.610708: Epoch 176 
2025-06-11 20:27:44.611225: Current learning rate: 0.00334 
2025-06-11 20:29:10.385406: train_loss -0.9549 
2025-06-11 20:29:10.386861: val_loss -0.8911 
2025-06-11 20:29:10.387337: Pseudo dice [np.float32(0.8856)] 
2025-06-11 20:29:10.387838: Epoch time: 85.78 s 
2025-06-11 20:29:11.488502:  
2025-06-11 20:29:11.489178: Epoch 177 
2025-06-11 20:29:11.489741: Current learning rate: 0.0033 
2025-06-11 20:30:37.271785: train_loss -0.9538 
2025-06-11 20:30:37.273232: val_loss -0.9018 
2025-06-11 20:30:37.273774: Pseudo dice [np.float32(0.901)] 
2025-06-11 20:30:37.274539: Epoch time: 85.79 s 
2025-06-11 20:30:38.408201:  
2025-06-11 20:30:38.409018: Epoch 178 
2025-06-11 20:30:38.409584: Current learning rate: 0.00326 
2025-06-11 20:32:04.154104: train_loss -0.9557 
2025-06-11 20:32:04.155534: val_loss -0.8934 
2025-06-11 20:32:04.156138: Pseudo dice [np.float32(0.8926)] 
2025-06-11 20:32:04.156732: Epoch time: 85.75 s 
2025-06-11 20:32:05.315295:  
2025-06-11 20:32:05.316077: Epoch 179 
2025-06-11 20:32:05.316636: Current learning rate: 0.00322 
2025-06-11 20:33:30.975961: train_loss -0.9556 
2025-06-11 20:33:30.977411: val_loss -0.8968 
2025-06-11 20:33:30.977913: Pseudo dice [np.float32(0.8937)] 
2025-06-11 20:33:30.978411: Epoch time: 85.66 s 
2025-06-11 20:33:32.081170:  
2025-06-11 20:33:32.082058: Epoch 180 
2025-06-11 20:33:32.082575: Current learning rate: 0.00318 
2025-06-11 20:34:57.749737: train_loss -0.9551 
2025-06-11 20:34:57.751571: val_loss -0.8974 
2025-06-11 20:34:57.752195: Pseudo dice [np.float32(0.8896)] 
2025-06-11 20:34:57.752783: Epoch time: 85.67 s 
2025-06-11 20:34:58.948161:  
2025-06-11 20:34:58.948974: Epoch 181 
2025-06-11 20:34:58.949489: Current learning rate: 0.00314 
2025-06-11 20:36:24.598970: train_loss -0.9544 
2025-06-11 20:36:24.600288: val_loss -0.9008 
2025-06-11 20:36:24.600848: Pseudo dice [np.float32(0.8983)] 
2025-06-11 20:36:24.601545: Epoch time: 85.65 s 
2025-06-11 20:36:25.723958:  
2025-06-11 20:36:25.724819: Epoch 182 
2025-06-11 20:36:25.725402: Current learning rate: 0.0031 
2025-06-11 20:37:51.370632: train_loss -0.9549 
2025-06-11 20:37:51.371927: val_loss -0.8926 
2025-06-11 20:37:51.372444: Pseudo dice [np.float32(0.8862)] 
2025-06-11 20:37:51.372944: Epoch time: 85.65 s 
2025-06-11 20:37:52.524190:  
2025-06-11 20:37:52.524987: Epoch 183 
2025-06-11 20:37:52.525522: Current learning rate: 0.00306 
2025-06-11 20:39:18.221964: train_loss -0.9545 
2025-06-11 20:39:18.223458: val_loss -0.8978 
2025-06-11 20:39:18.224173: Pseudo dice [np.float32(0.8898)] 
2025-06-11 20:39:18.224896: Epoch time: 85.7 s 
2025-06-11 20:39:19.362376:  
2025-06-11 20:39:19.363037: Epoch 184 
2025-06-11 20:39:19.363522: Current learning rate: 0.00302 
2025-06-11 20:40:44.974180: train_loss -0.9546 
2025-06-11 20:40:44.975535: val_loss -0.8971 
2025-06-11 20:40:44.976146: Pseudo dice [np.float32(0.893)] 
2025-06-11 20:40:44.976757: Epoch time: 85.61 s 
2025-06-11 20:40:46.124553:  
2025-06-11 20:40:46.125262: Epoch 185 
2025-06-11 20:40:46.125801: Current learning rate: 0.00297 
2025-06-11 20:42:11.764441: train_loss -0.9556 
2025-06-11 20:42:11.766099: val_loss -0.8917 
2025-06-11 20:42:11.766818: Pseudo dice [np.float32(0.8831)] 
2025-06-11 20:42:11.767502: Epoch time: 85.64 s 
2025-06-11 20:42:12.922047:  
2025-06-11 20:42:12.922755: Epoch 186 
2025-06-11 20:42:12.923320: Current learning rate: 0.00293 
2025-06-11 20:43:38.622561: train_loss -0.9554 
2025-06-11 20:43:38.623934: val_loss -0.8981 
2025-06-11 20:43:38.624450: Pseudo dice [np.float32(0.8979)] 
2025-06-11 20:43:38.624980: Epoch time: 85.7 s 
2025-06-11 20:43:39.786100:  
2025-06-11 20:43:39.786855: Epoch 187 
2025-06-11 20:43:39.787364: Current learning rate: 0.00289 
2025-06-11 20:45:05.514611: train_loss -0.9553 
2025-06-11 20:45:05.516104: val_loss -0.8936 
2025-06-11 20:45:05.516731: Pseudo dice [np.float32(0.8913)] 
2025-06-11 20:45:05.517336: Epoch time: 85.73 s 
2025-06-11 20:45:06.666714:  
2025-06-11 20:45:06.667419: Epoch 188 
2025-06-11 20:45:06.667953: Current learning rate: 0.00285 
2025-06-11 20:46:32.378366: train_loss -0.9547 
2025-06-11 20:46:32.380056: val_loss -0.892 
2025-06-11 20:46:32.380755: Pseudo dice [np.float32(0.886)] 
2025-06-11 20:46:32.381380: Epoch time: 85.71 s 
2025-06-11 20:46:33.517101:  
2025-06-11 20:46:33.517924: Epoch 189 
2025-06-11 20:46:33.518484: Current learning rate: 0.00281 
2025-06-11 20:47:59.240341: train_loss -0.9543 
2025-06-11 20:47:59.241938: val_loss -0.8951 
2025-06-11 20:47:59.242511: Pseudo dice [np.float32(0.8908)] 
2025-06-11 20:47:59.243116: Epoch time: 85.73 s 
2025-06-11 20:48:00.435872:  
2025-06-11 20:48:00.436762: Epoch 190 
2025-06-11 20:48:00.437344: Current learning rate: 0.00277 
2025-06-11 20:49:26.097852: train_loss -0.9549 
2025-06-11 20:49:26.099372: val_loss -0.897 
2025-06-11 20:49:26.100043: Pseudo dice [np.float32(0.8967)] 
2025-06-11 20:49:26.100672: Epoch time: 85.66 s 
2025-06-11 20:49:27.269550:  
2025-06-11 20:49:27.270288: Epoch 191 
2025-06-11 20:49:27.270826: Current learning rate: 0.00273 
2025-06-11 20:50:52.930943: train_loss -0.9562 
2025-06-11 20:50:52.932287: val_loss -0.8944 
2025-06-11 20:50:52.932784: Pseudo dice [np.float32(0.895)] 
2025-06-11 20:50:52.933340: Epoch time: 85.66 s 
2025-06-11 20:50:54.069440:  
2025-06-11 20:50:54.070172: Epoch 192 
2025-06-11 20:50:54.070806: Current learning rate: 0.00268 
2025-06-11 20:52:19.770044: train_loss -0.9546 
2025-06-11 20:52:19.771648: val_loss -0.8964 
2025-06-11 20:52:19.772464: Pseudo dice [np.float32(0.8909)] 
2025-06-11 20:52:19.773375: Epoch time: 85.7 s 
2025-06-11 20:52:22.198284:  
2025-06-11 20:52:22.199172: Epoch 193 
2025-06-11 20:52:22.199699: Current learning rate: 0.00264 
2025-06-11 20:53:47.907889: train_loss -0.9544 
2025-06-11 20:53:47.909619: val_loss -0.8977 
2025-06-11 20:53:47.910324: Pseudo dice [np.float32(0.8969)] 
2025-06-11 20:53:47.911033: Epoch time: 85.71 s 
2025-06-11 20:53:49.071565:  
2025-06-11 20:53:49.072498: Epoch 194 
2025-06-11 20:53:49.073083: Current learning rate: 0.0026 
2025-06-11 20:55:14.861541: train_loss -0.9564 
2025-06-11 20:55:14.863186: val_loss -0.8941 
2025-06-11 20:55:14.863796: Pseudo dice [np.float32(0.8917)] 
2025-06-11 20:55:14.864606: Epoch time: 85.79 s 
2025-06-11 20:55:15.985543:  
2025-06-11 20:55:15.986306: Epoch 195 
2025-06-11 20:55:15.986904: Current learning rate: 0.00256 
2025-06-11 20:56:41.773246: train_loss -0.9565 
2025-06-11 20:56:41.774618: val_loss -0.891 
2025-06-11 20:56:41.775157: Pseudo dice [np.float32(0.8885)] 
2025-06-11 20:56:41.775752: Epoch time: 85.79 s 
2025-06-11 20:56:42.904283:  
2025-06-11 20:56:42.905000: Epoch 196 
2025-06-11 20:56:42.905483: Current learning rate: 0.00252 
2025-06-11 20:58:08.666190: train_loss -0.9543 
2025-06-11 20:58:08.668252: val_loss -0.8954 
2025-06-11 20:58:08.669023: Pseudo dice [np.float32(0.8918)] 
2025-06-11 20:58:08.669793: Epoch time: 85.76 s 
2025-06-11 20:58:09.814826:  
2025-06-11 20:58:09.815854: Epoch 197 
2025-06-11 20:58:09.816389: Current learning rate: 0.00248 
2025-06-11 20:59:35.554440: train_loss -0.9559 
2025-06-11 20:59:35.556406: val_loss -0.9032 
2025-06-11 20:59:35.557131: Pseudo dice [np.float32(0.9019)] 
2025-06-11 20:59:35.557728: Epoch time: 85.74 s 
2025-06-11 20:59:36.684314:  
2025-06-11 20:59:36.685044: Epoch 198 
2025-06-11 20:59:36.685600: Current learning rate: 0.00243 
2025-06-11 21:01:02.413430: train_loss -0.9563 
2025-06-11 21:01:02.414787: val_loss -0.8966 
2025-06-11 21:01:02.415282: Pseudo dice [np.float32(0.8926)] 
2025-06-11 21:01:02.415738: Epoch time: 85.73 s 
2025-06-11 21:01:03.563882:  
2025-06-11 21:01:03.564900: Epoch 199 
2025-06-11 21:01:03.565369: Current learning rate: 0.00239 
2025-06-11 21:02:29.253243: train_loss -0.9563 
2025-06-11 21:02:29.254625: val_loss -0.8938 
2025-06-11 21:02:29.255243: Pseudo dice [np.float32(0.8872)] 
2025-06-11 21:02:29.255865: Epoch time: 85.69 s 
2025-06-11 21:02:31.832505:  
2025-06-11 21:02:31.833295: Epoch 200 
2025-06-11 21:02:31.834070: Current learning rate: 0.00235 
2025-06-11 21:03:57.538007: train_loss -0.9563 
2025-06-11 21:03:57.539382: val_loss -0.8968 
2025-06-11 21:03:57.539873: Pseudo dice [np.float32(0.8951)] 
2025-06-11 21:03:57.540328: Epoch time: 85.71 s 
2025-06-11 21:03:58.698214:  
2025-06-11 21:03:58.699042: Epoch 201 
2025-06-11 21:03:58.699576: Current learning rate: 0.00231 
2025-06-11 21:05:24.447615: train_loss -0.9567 
2025-06-11 21:05:24.449861: val_loss -0.8951 
2025-06-11 21:05:24.450624: Pseudo dice [np.float32(0.8901)] 
2025-06-11 21:05:24.451401: Epoch time: 85.75 s 
2025-06-11 21:05:25.618798:  
2025-06-11 21:05:25.619596: Epoch 202 
2025-06-11 21:05:25.620135: Current learning rate: 0.00226 
2025-06-11 21:06:51.394546: train_loss -0.9567 
2025-06-11 21:06:51.396580: val_loss -0.8916 
2025-06-11 21:06:51.397274: Pseudo dice [np.float32(0.887)] 
2025-06-11 21:06:51.398177: Epoch time: 85.78 s 
2025-06-11 21:06:52.549622:  
2025-06-11 21:06:52.551047: Epoch 203 
2025-06-11 21:06:52.551772: Current learning rate: 0.00222 
2025-06-11 21:08:18.270239: train_loss -0.9563 
2025-06-11 21:08:18.271609: val_loss -0.8956 
2025-06-11 21:08:18.272122: Pseudo dice [np.float32(0.8932)] 
2025-06-11 21:08:18.272714: Epoch time: 85.72 s 
2025-06-11 21:08:19.427176:  
2025-06-11 21:08:19.427968: Epoch 204 
2025-06-11 21:08:19.428519: Current learning rate: 0.00218 
2025-06-11 21:09:45.154825: train_loss -0.9568 
2025-06-11 21:09:45.156380: val_loss -0.8948 
2025-06-11 21:09:45.156990: Pseudo dice [np.float32(0.8921)] 
2025-06-11 21:09:45.157583: Epoch time: 85.73 s 
2025-06-11 21:09:46.305018:  
2025-06-11 21:09:46.305778: Epoch 205 
2025-06-11 21:09:46.306365: Current learning rate: 0.00214 
2025-06-11 21:11:12.068844: train_loss -0.9566 
2025-06-11 21:11:12.070269: val_loss -0.8921 
2025-06-11 21:11:12.070889: Pseudo dice [np.float32(0.8916)] 
2025-06-11 21:11:12.071562: Epoch time: 85.77 s 
2025-06-11 21:11:13.187507:  
2025-06-11 21:11:13.188374: Epoch 206 
2025-06-11 21:11:13.189006: Current learning rate: 0.00209 
2025-06-11 21:12:38.872636: train_loss -0.9559 
2025-06-11 21:12:38.873977: val_loss -0.894 
2025-06-11 21:12:38.874650: Pseudo dice [np.float32(0.8913)] 
2025-06-11 21:12:38.875251: Epoch time: 85.69 s 
2025-06-11 21:12:40.038805:  
2025-06-11 21:12:40.039591: Epoch 207 
2025-06-11 21:12:40.040177: Current learning rate: 0.00205 
2025-06-11 21:14:05.828591: train_loss -0.9575 
2025-06-11 21:14:05.830415: val_loss -0.8934 
2025-06-11 21:14:05.830915: Pseudo dice [np.float32(0.8903)] 
2025-06-11 21:14:05.831437: Epoch time: 85.79 s 
2025-06-11 21:14:06.941592:  
2025-06-11 21:14:06.942391: Epoch 208 
2025-06-11 21:14:06.943026: Current learning rate: 0.00201 
2025-06-11 21:15:32.570866: train_loss -0.9565 
2025-06-11 21:15:32.572538: val_loss -0.8963 
2025-06-11 21:15:32.573008: Pseudo dice [np.float32(0.8955)] 
2025-06-11 21:15:32.573452: Epoch time: 85.63 s 
2025-06-11 21:15:33.669183:  
2025-06-11 21:15:33.670062: Epoch 209 
2025-06-11 21:15:33.670908: Current learning rate: 0.00196 
2025-06-11 21:16:59.363595: train_loss -0.9569 
2025-06-11 21:16:59.365676: val_loss -0.8945 
2025-06-11 21:16:59.366203: Pseudo dice [np.float32(0.8933)] 
2025-06-11 21:16:59.366938: Epoch time: 85.7 s 
2025-06-11 21:17:00.510530:  
2025-06-11 21:17:00.511374: Epoch 210 
2025-06-11 21:17:00.512005: Current learning rate: 0.00192 
2025-06-11 21:18:26.123606: train_loss -0.9572 
2025-06-11 21:18:26.125008: val_loss -0.8932 
2025-06-11 21:18:26.125434: Pseudo dice [np.float32(0.8939)] 
2025-06-11 21:18:26.126042: Epoch time: 85.62 s 
2025-06-11 21:18:27.214532:  
2025-06-11 21:18:27.215449: Epoch 211 
2025-06-11 21:18:27.216026: Current learning rate: 0.00188 
2025-06-11 21:19:52.827498: train_loss -0.9567 
2025-06-11 21:19:52.828904: val_loss -0.8991 
2025-06-11 21:19:52.829438: Pseudo dice [np.float32(0.8964)] 
2025-06-11 21:19:52.829999: Epoch time: 85.62 s 
2025-06-11 21:19:53.926972:  
2025-06-11 21:19:53.927872: Epoch 212 
2025-06-11 21:19:53.928483: Current learning rate: 0.00184 
2025-06-11 21:21:19.678246: train_loss -0.9585 
2025-06-11 21:21:19.679815: val_loss -0.8954 
2025-06-11 21:21:19.680431: Pseudo dice [np.float32(0.8957)] 
2025-06-11 21:21:19.681203: Epoch time: 85.75 s 
2025-06-11 21:21:20.816281:  
2025-06-11 21:21:20.817064: Epoch 213 
2025-06-11 21:21:20.818197: Current learning rate: 0.00179 
2025-06-11 21:22:46.373938: train_loss -0.9564 
2025-06-11 21:22:46.375250: val_loss -0.8974 
2025-06-11 21:22:46.375770: Pseudo dice [np.float32(0.8931)] 
2025-06-11 21:22:46.376268: Epoch time: 85.56 s 
2025-06-11 21:22:47.477636:  
2025-06-11 21:22:47.478389: Epoch 214 
2025-06-11 21:22:47.478901: Current learning rate: 0.00175 
2025-06-11 21:24:13.133869: train_loss -0.9578 
2025-06-11 21:24:13.135240: val_loss -0.894 
2025-06-11 21:24:13.135811: Pseudo dice [np.float32(0.8925)] 
2025-06-11 21:24:13.136406: Epoch time: 85.66 s 
2025-06-11 21:24:14.202523:  
2025-06-11 21:24:14.203148: Epoch 215 
2025-06-11 21:24:14.203681: Current learning rate: 0.0017 
2025-06-11 21:25:39.829518: train_loss -0.9577 
2025-06-11 21:25:39.831085: val_loss -0.9016 
2025-06-11 21:25:39.831571: Pseudo dice [np.float32(0.8988)] 
2025-06-11 21:25:39.832113: Epoch time: 85.63 s 
2025-06-11 21:25:40.914069:  
2025-06-11 21:25:40.914845: Epoch 216 
2025-06-11 21:25:40.915363: Current learning rate: 0.00166 
2025-06-11 21:27:06.650792: train_loss -0.9581 
2025-06-11 21:27:06.652326: val_loss -0.8979 
2025-06-11 21:27:06.652960: Pseudo dice [np.float32(0.8936)] 
2025-06-11 21:27:06.653648: Epoch time: 85.74 s 
2025-06-11 21:27:07.802902:  
2025-06-11 21:27:07.803710: Epoch 217 
2025-06-11 21:27:07.804266: Current learning rate: 0.00162 
2025-06-11 21:28:33.530406: train_loss -0.9582 
2025-06-11 21:28:33.531806: val_loss -0.8988 
2025-06-11 21:28:33.532337: Pseudo dice [np.float32(0.8984)] 
2025-06-11 21:28:33.532949: Epoch time: 85.73 s 
2025-06-11 21:28:35.989005:  
2025-06-11 21:28:35.989928: Epoch 218 
2025-06-11 21:28:35.990443: Current learning rate: 0.00157 
2025-06-11 21:30:01.684222: train_loss -0.9575 
2025-06-11 21:30:01.686004: val_loss -0.8968 
2025-06-11 21:30:01.686695: Pseudo dice [np.float32(0.895)] 
2025-06-11 21:30:01.687238: Epoch time: 85.7 s 
2025-06-11 21:30:02.802303:  
2025-06-11 21:30:02.803163: Epoch 219 
2025-06-11 21:30:02.803786: Current learning rate: 0.00153 
2025-06-11 21:31:28.477185: train_loss -0.9567 
2025-06-11 21:31:28.479101: val_loss -0.8944 
2025-06-11 21:31:28.479720: Pseudo dice [np.float32(0.8935)] 
2025-06-11 21:31:28.480426: Epoch time: 85.68 s 
2025-06-11 21:31:29.611953:  
2025-06-11 21:31:29.612895: Epoch 220 
2025-06-11 21:31:29.613538: Current learning rate: 0.00148 
2025-06-11 21:32:55.282658: train_loss -0.9579 
2025-06-11 21:32:55.284076: val_loss -0.8978 
2025-06-11 21:32:55.284654: Pseudo dice [np.float32(0.8954)] 
2025-06-11 21:32:55.285396: Epoch time: 85.67 s 
2025-06-11 21:32:56.415465:  
2025-06-11 21:32:56.416187: Epoch 221 
2025-06-11 21:32:56.416720: Current learning rate: 0.00144 
2025-06-11 21:34:22.137829: train_loss -0.9595 
2025-06-11 21:34:22.139443: val_loss -0.8957 
2025-06-11 21:34:22.140029: Pseudo dice [np.float32(0.896)] 
2025-06-11 21:34:22.141125: Epoch time: 85.73 s 
2025-06-11 21:34:23.237058:  
2025-06-11 21:34:23.238015: Epoch 222 
2025-06-11 21:34:23.238563: Current learning rate: 0.00139 
2025-06-11 21:35:49.024324: train_loss -0.958 
2025-06-11 21:35:49.025828: val_loss -0.9033 
2025-06-11 21:35:49.026364: Pseudo dice [np.float32(0.9033)] 
2025-06-11 21:35:49.026906: Epoch time: 85.79 s 
2025-06-11 21:35:50.088302:  
2025-06-11 21:35:50.089171: Epoch 223 
2025-06-11 21:35:50.089694: Current learning rate: 0.00135 
2025-06-11 21:37:15.807623: train_loss -0.957 
2025-06-11 21:37:15.809254: val_loss -0.8966 
2025-06-11 21:37:15.809828: Pseudo dice [np.float32(0.8956)] 
2025-06-11 21:37:15.810399: Epoch time: 85.72 s 
2025-06-11 21:37:16.904660:  
2025-06-11 21:37:16.905560: Epoch 224 
2025-06-11 21:37:16.906139: Current learning rate: 0.0013 
2025-06-11 21:38:42.627698: train_loss -0.9573 
2025-06-11 21:38:42.629246: val_loss -0.8971 
2025-06-11 21:38:42.629897: Pseudo dice [np.float32(0.8952)] 
2025-06-11 21:38:42.630581: Epoch time: 85.73 s 
2025-06-11 21:38:43.781436:  
2025-06-11 21:38:43.782342: Epoch 225 
2025-06-11 21:38:43.783256: Current learning rate: 0.00126 
2025-06-11 21:40:09.641105: train_loss -0.959 
2025-06-11 21:40:09.642722: val_loss -0.8949 
2025-06-11 21:40:09.643242: Pseudo dice [np.float32(0.8893)] 
2025-06-11 21:40:09.643731: Epoch time: 85.86 s 
2025-06-11 21:40:10.779999:  
2025-06-11 21:40:10.780728: Epoch 226 
2025-06-11 21:40:10.781248: Current learning rate: 0.00121 
2025-06-11 21:41:36.610839: train_loss -0.9586 
2025-06-11 21:41:36.612385: val_loss -0.8999 
2025-06-11 21:41:36.612895: Pseudo dice [np.float32(0.8976)] 
2025-06-11 21:41:36.613493: Epoch time: 85.83 s 
2025-06-11 21:41:37.679051:  
2025-06-11 21:41:37.679807: Epoch 227 
2025-06-11 21:41:37.680340: Current learning rate: 0.00117 
2025-06-11 21:43:03.407480: train_loss -0.9588 
2025-06-11 21:43:03.408900: val_loss -0.8979 
2025-06-11 21:43:03.409475: Pseudo dice [np.float32(0.8928)] 
2025-06-11 21:43:03.410375: Epoch time: 85.73 s 
2025-06-11 21:43:04.582055:  
2025-06-11 21:43:04.583015: Epoch 228 
2025-06-11 21:43:04.584101: Current learning rate: 0.00112 
2025-06-11 21:44:30.453644: train_loss -0.9589 
2025-06-11 21:44:30.455107: val_loss -0.8983 
2025-06-11 21:44:30.455672: Pseudo dice [np.float32(0.8956)] 
2025-06-11 21:44:30.456278: Epoch time: 85.87 s 
2025-06-11 21:44:31.541039:  
2025-06-11 21:44:31.541863: Epoch 229 
2025-06-11 21:44:31.542377: Current learning rate: 0.00108 
2025-06-11 21:45:57.162545: train_loss -0.9587 
2025-06-11 21:45:57.164461: val_loss -0.8968 
2025-06-11 21:45:57.165129: Pseudo dice [np.float32(0.8921)] 
2025-06-11 21:45:57.165709: Epoch time: 85.62 s 
2025-06-11 21:45:58.239823:  
2025-06-11 21:45:58.240741: Epoch 230 
2025-06-11 21:45:58.241310: Current learning rate: 0.00103 
2025-06-11 21:47:23.915803: train_loss -0.9586 
2025-06-11 21:47:23.917442: val_loss -0.8992 
2025-06-11 21:47:23.918032: Pseudo dice [np.float32(0.8968)] 
2025-06-11 21:47:23.918630: Epoch time: 85.68 s 
2025-06-11 21:47:25.004975:  
2025-06-11 21:47:25.005816: Epoch 231 
2025-06-11 21:47:25.006360: Current learning rate: 0.00098 
2025-06-11 21:48:50.668751: train_loss -0.9605 
2025-06-11 21:48:50.670071: val_loss -0.8984 
2025-06-11 21:48:50.670596: Pseudo dice [np.float32(0.8957)] 
2025-06-11 21:48:50.671152: Epoch time: 85.67 s 
2025-06-11 21:48:51.753312:  
2025-06-11 21:48:51.754207: Epoch 232 
2025-06-11 21:48:51.754883: Current learning rate: 0.00094 
2025-06-11 21:50:17.476889: train_loss -0.9584 
2025-06-11 21:50:17.478599: val_loss -0.8941 
2025-06-11 21:50:17.479331: Pseudo dice [np.float32(0.8939)] 
2025-06-11 21:50:17.480188: Epoch time: 85.73 s 
2025-06-11 21:50:18.607125:  
2025-06-11 21:50:18.607929: Epoch 233 
2025-06-11 21:50:18.608500: Current learning rate: 0.00089 
2025-06-11 21:51:44.346753: train_loss -0.9593 
2025-06-11 21:51:44.348276: val_loss -0.8984 
2025-06-11 21:51:44.348835: Pseudo dice [np.float32(0.8948)] 
2025-06-11 21:51:44.349550: Epoch time: 85.74 s 
2025-06-11 21:51:45.464978:  
2025-06-11 21:51:45.465853: Epoch 234 
2025-06-11 21:51:45.466443: Current learning rate: 0.00084 
2025-06-11 21:53:11.309289: train_loss -0.9596 
2025-06-11 21:53:11.312123: val_loss -0.8966 
2025-06-11 21:53:11.312943: Pseudo dice [np.float32(0.8944)] 
2025-06-11 21:53:11.313993: Epoch time: 85.85 s 
2025-06-11 21:53:12.440735:  
2025-06-11 21:53:12.441445: Epoch 235 
2025-06-11 21:53:12.441916: Current learning rate: 0.00079 
2025-06-11 21:54:38.109488: train_loss -0.9595 
2025-06-11 21:54:38.110915: val_loss -0.8978 
2025-06-11 21:54:38.111444: Pseudo dice [np.float32(0.8969)] 
2025-06-11 21:54:38.112011: Epoch time: 85.67 s 
2025-06-11 21:54:39.241752:  
2025-06-11 21:54:39.242468: Epoch 236 
2025-06-11 21:54:39.242993: Current learning rate: 0.00075 
2025-06-11 21:56:04.905639: train_loss -0.96 
2025-06-11 21:56:04.906981: val_loss -0.8991 
2025-06-11 21:56:04.907470: Pseudo dice [np.float32(0.8987)] 
2025-06-11 21:56:04.908052: Epoch time: 85.67 s 
2025-06-11 21:56:05.983816:  
2025-06-11 21:56:05.984603: Epoch 237 
2025-06-11 21:56:05.985108: Current learning rate: 0.0007 
2025-06-11 21:57:31.707017: train_loss -0.9594 
2025-06-11 21:57:31.708391: val_loss -0.9019 
2025-06-11 21:57:31.709104: Pseudo dice [np.float32(0.8988)] 
2025-06-11 21:57:31.709718: Epoch time: 85.73 s 
2025-06-11 21:57:32.818033:  
2025-06-11 21:57:32.818763: Epoch 238 
2025-06-11 21:57:32.819356: Current learning rate: 0.00065 
2025-06-11 21:58:58.597383: train_loss -0.9599 
2025-06-11 21:58:58.599288: val_loss -0.8999 
2025-06-11 21:58:58.600047: Pseudo dice [np.float32(0.8984)] 
2025-06-11 21:58:58.600673: Epoch time: 85.78 s 
2025-06-11 21:58:59.728112:  
2025-06-11 21:58:59.728938: Epoch 239 
2025-06-11 21:58:59.729635: Current learning rate: 0.0006 
2025-06-11 22:00:25.513154: train_loss -0.96 
2025-06-11 22:00:25.514767: val_loss -0.9025 
2025-06-11 22:00:25.515852: Pseudo dice [np.float32(0.9004)] 
2025-06-11 22:00:25.516555: Epoch time: 85.79 s 
2025-06-11 22:00:26.645483:  
2025-06-11 22:00:26.646425: Epoch 240 
2025-06-11 22:00:26.647057: Current learning rate: 0.00055 
2025-06-11 22:01:52.340426: train_loss -0.9599 
2025-06-11 22:01:52.341880: val_loss -0.8953 
2025-06-11 22:01:52.342327: Pseudo dice [np.float32(0.8933)] 
2025-06-11 22:01:52.342850: Epoch time: 85.7 s 
2025-06-11 22:01:53.490266:  
2025-06-11 22:01:53.491123: Epoch 241 
2025-06-11 22:01:53.491675: Current learning rate: 0.0005 
2025-06-11 22:03:19.192988: train_loss -0.9607 
2025-06-11 22:03:19.194718: val_loss -0.8992 
2025-06-11 22:03:19.195226: Pseudo dice [np.float32(0.8963)] 
2025-06-11 22:03:19.195826: Epoch time: 85.71 s 
2025-06-11 22:03:20.303960:  
2025-06-11 22:03:20.304719: Epoch 242 
2025-06-11 22:03:20.305235: Current learning rate: 0.00045 
2025-06-11 22:04:46.019660: train_loss -0.9607 
2025-06-11 22:04:46.021579: val_loss -0.8961 
2025-06-11 22:04:46.022368: Pseudo dice [np.float32(0.8924)] 
2025-06-11 22:04:46.023110: Epoch time: 85.72 s 
2025-06-11 22:04:47.145972:  
2025-06-11 22:04:47.146899: Epoch 243 
2025-06-11 22:04:47.147537: Current learning rate: 0.0004 
2025-06-11 22:06:12.836926: train_loss -0.9598 
2025-06-11 22:06:12.838253: val_loss -0.8988 
2025-06-11 22:06:12.838763: Pseudo dice [np.float32(0.8988)] 
2025-06-11 22:06:12.839308: Epoch time: 85.69 s 
2025-06-11 22:06:13.968009:  
2025-06-11 22:06:13.968687: Epoch 244 
2025-06-11 22:06:13.969314: Current learning rate: 0.00035 
2025-06-11 22:07:39.749998: train_loss -0.9594 
2025-06-11 22:07:39.751484: val_loss -0.8972 
2025-06-11 22:07:39.752036: Pseudo dice [np.float32(0.8946)] 
2025-06-11 22:07:39.752578: Epoch time: 85.79 s 
2025-06-11 22:07:42.177273:  
2025-06-11 22:07:42.178257: Epoch 245 
2025-06-11 22:07:42.178784: Current learning rate: 0.0003 
2025-06-11 22:09:07.936440: train_loss -0.9594 
2025-06-11 22:09:07.937927: val_loss -0.9014 
2025-06-11 22:09:07.938490: Pseudo dice [np.float32(0.8958)] 
2025-06-11 22:09:07.939063: Epoch time: 85.76 s 
2025-06-11 22:09:09.047182:  
2025-06-11 22:09:09.047982: Epoch 246 
2025-06-11 22:09:09.048489: Current learning rate: 0.00024 
2025-06-11 22:10:34.817854: train_loss -0.9609 
2025-06-11 22:10:34.819436: val_loss -0.9013 
2025-06-11 22:10:34.819977: Pseudo dice [np.float32(0.8978)] 
2025-06-11 22:10:34.820713: Epoch time: 85.77 s 
2025-06-11 22:10:35.953463:  
2025-06-11 22:10:35.954274: Epoch 247 
2025-06-11 22:10:35.954783: Current learning rate: 0.00019 
2025-06-11 22:12:01.779528: train_loss -0.9606 
2025-06-11 22:12:01.781233: val_loss -0.8996 
2025-06-11 22:12:01.781882: Pseudo dice [np.float32(0.8965)] 
2025-06-11 22:12:01.782499: Epoch time: 85.83 s 
2025-06-11 22:12:02.924653:  
2025-06-11 22:12:02.925416: Epoch 248 
2025-06-11 22:12:02.925982: Current learning rate: 0.00013 
2025-06-11 22:13:28.650947: train_loss -0.961 
2025-06-11 22:13:28.652656: val_loss -0.8971 
2025-06-11 22:13:28.653358: Pseudo dice [np.float32(0.8948)] 
2025-06-11 22:13:28.653982: Epoch time: 85.73 s 
2025-06-11 22:13:29.797801:  
2025-06-11 22:13:29.798614: Epoch 249 
2025-06-11 22:13:29.799144: Current learning rate: 7e-05 
2025-06-11 22:14:55.514513: train_loss -0.9614 
2025-06-11 22:14:55.515876: val_loss -0.899 
2025-06-11 22:14:55.516342: Pseudo dice [np.float32(0.8956)] 
2025-06-11 22:14:55.516858: Epoch time: 85.72 s 
2025-06-11 22:14:58.050930: Training done. 
2025-06-11 22:14:58.161752: Using splits from existing split file: /home/woody/mfdp/mfdp112h/nnunet_bhautik/preprocessing/Dataset001_VesselDetection/splits_final.json 
2025-06-11 22:14:58.163880: The split file contains 5 splits. 
2025-06-11 22:14:58.164440: Desired fold for training: 0 
2025-06-11 22:14:58.164960: This split has 84 training and 21 validation cases. 
2025-06-11 22:14:58.165602: predicting VesselDetection_0005 
2025-06-11 22:14:58.179364: VesselDetection_0005, shape torch.Size([1, 1, 3, 3]), rank 0 
2025-06-11 22:15:42.754349: predicting VesselDetection_0010 
2025-06-11 22:15:42.759434: VesselDetection_0010, shape torch.Size([1, 1, 191, 198]), rank 0 
2025-06-11 22:15:42.824653: predicting VesselDetection_0014 
2025-06-11 22:15:42.827887: VesselDetection_0014, shape torch.Size([1, 1, 191, 198]), rank 0 
2025-06-11 22:15:42.912194: predicting VesselDetection_0020 
2025-06-11 22:15:42.920846: VesselDetection_0020, shape torch.Size([1, 1, 206, 206]), rank 0 
2025-06-11 22:15:42.990727: predicting VesselDetection_0021 
2025-06-11 22:15:42.994049: VesselDetection_0021, shape torch.Size([1, 1, 206, 206]), rank 0 
2025-06-11 22:15:43.066550: predicting VesselDetection_0026 
2025-06-11 22:15:43.070080: VesselDetection_0026, shape torch.Size([1, 1, 195, 197]), rank 0 
2025-06-11 22:15:43.148649: predicting VesselDetection_0034 
2025-06-11 22:15:43.152138: VesselDetection_0034, shape torch.Size([1, 1, 195, 197]), rank 0 
2025-06-11 22:15:43.212821: predicting VesselDetection_0038 
2025-06-11 22:15:43.220202: VesselDetection_0038, shape torch.Size([1, 1, 206, 206]), rank 0 
2025-06-11 22:15:43.300052: predicting VesselDetection_0040 
2025-06-11 22:15:43.303871: VesselDetection_0040, shape torch.Size([1, 1, 206, 206]), rank 0 
2025-06-11 22:15:43.376121: predicting VesselDetection_0041 
2025-06-11 22:15:43.380090: VesselDetection_0041, shape torch.Size([1, 1, 198, 199]), rank 0 
2025-06-11 22:15:43.449697: predicting VesselDetection_0045 
2025-06-11 22:15:43.453129: VesselDetection_0045, shape torch.Size([1, 1, 198, 199]), rank 0 
2025-06-11 22:15:43.504528: predicting VesselDetection_0048 
2025-06-11 22:15:43.507583: VesselDetection_0048, shape torch.Size([1, 1, 198, 199]), rank 0 
2025-06-11 22:15:43.557164: predicting VesselDetection_0049 
2025-06-11 22:15:43.560341: VesselDetection_0049, shape torch.Size([1, 1, 198, 199]), rank 0 
2025-06-11 22:15:43.625890: predicting VesselDetection_0055 
2025-06-11 22:15:43.630798: VesselDetection_0055, shape torch.Size([1, 1, 195, 197]), rank 0 
2025-06-11 22:15:43.711275: predicting VesselDetection_0059 
2025-06-11 22:15:43.714866: VesselDetection_0059, shape torch.Size([1, 1, 195, 197]), rank 0 
2025-06-11 22:15:43.779405: predicting VesselDetection_0063 
2025-06-11 22:15:43.782523: VesselDetection_0063, shape torch.Size([1, 1, 198, 202]), rank 0 
2025-06-11 22:15:43.858145: predicting VesselDetection_0073 
2025-06-11 22:15:43.861795: VesselDetection_0073, shape torch.Size([1, 1, 196, 201]), rank 0 
2025-06-11 22:15:43.920689: predicting VesselDetection_0077 
2025-06-11 22:15:43.924068: VesselDetection_0077, shape torch.Size([1, 1, 204, 206]), rank 0 
2025-06-11 22:15:43.976295: predicting VesselDetection_0079 
2025-06-11 22:15:43.979345: VesselDetection_0079, shape torch.Size([1, 1, 204, 206]), rank 0 
2025-06-11 22:15:44.030149: predicting VesselDetection_0088 
2025-06-11 22:15:44.033401: VesselDetection_0088, shape torch.Size([1, 1, 206, 206]), rank 0 
2025-06-11 22:15:44.081479: predicting VesselDetection_0090 
2025-06-11 22:15:44.085046: VesselDetection_0090, shape torch.Size([1, 1, 206, 206]), rank 0 
2025-06-11 22:15:54.620262: Validation complete 
2025-06-11 22:15:54.620810: Mean Validation Dice:  0.8995763415164602 
